{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Features Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_dir = Path().resolve().parent\n",
    "statistic_dir = project_dir / \"statistics\"\n",
    "script_dir = project_dir / \"scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(script_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from visualization import (\n",
    "    plot_all_layers,\n",
    "    plot_all_lang_feature_overlap,\n",
    "    plot_lang_feature_overlap_trend,\n",
    "    plot_all_co_occurrence,\n",
    "    plot_all_cross_co_occurrence,\n",
    "    plot_all_count_box_plots,\n",
    "    plot_lape_result,\n",
    "    plot_umap,\n",
    "    plot_ppl_change_matrix,\n",
    "    generate_ppl_change_matrix,\n",
    "    plot_metrics,\n",
    "    plot_features_similarity,\n",
    "    plot_sae_features_entropy_score_correlation,\n",
    ")\n",
    "\n",
    "from feature_visualizer import (\n",
    "    generate_feature_activations_visualization,\n",
    ")\n",
    "\n",
    "from loader import (\n",
    "    load_layer_to_summary,\n",
    "    load_lang_to_dataset_token_activations,\n",
    "    load_lang_to_dataset_token_activations_aggregate,\n",
    "    load_all_interpretations,\n",
    "    load_sae_features_info_df,\n",
    "    load_lang_to_sae_features_info,\n",
    ")\n",
    "\n",
    "from const import (\n",
    "    lang_choices_to_qualified_name, \n",
    "    layer_to_index, \n",
    "    lang_choices_to_qualified_name\n",
    "    )\n",
    "\n",
    "from delphi.log.result_analysis import get_metrics_per_latent, load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_xnli = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"facebook/xnli\",\n",
    "    \"split\": \"train\",\n",
    "    \"languages\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"hi\",\n",
    "        \"es\",\n",
    "        \"th\",\n",
    "        \"bg\",\n",
    "        \"ru\",\n",
    "        \"tr\",\n",
    "        \"vi\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_pawsx = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"google-research-datasets/paws-x\",\n",
    "    \"split\": \"train\",\n",
    "    \"languages\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"es\",\n",
    "        \"ja\",\n",
    "        \"ko\",\n",
    "        \"zh\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_flores = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"openlanguagedata/flores_plus\",\n",
    "    \"split\": \"dev\",\n",
    "    \"languages\": [\n",
    "        \"eng_Latn\",\n",
    "        \"deu_Latn\",\n",
    "        \"fra_Latn\",\n",
    "        \"ita_Latn\",\n",
    "        \"por_Latn\",\n",
    "        \"hin_Deva\",\n",
    "        \"spa_Latn\",\n",
    "        \"tha_Thai\",\n",
    "        \"bul_Cyrl\",\n",
    "        \"rus_Cyrl\",\n",
    "        \"tur_Latn\",\n",
    "        \"vie_Latn\",\n",
    "        \"jpn_Jpan\",\n",
    "        \"kor_Hang\",\n",
    "        \"cmn_Hans\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_summary_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")\n",
    "\n",
    "df_layers_llama_xnli = load_layer_to_summary(\n",
    "    data_path_summary_xnli, config_xnli[\"layers\"], config_xnli[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(df_layers_llama_xnli, config_xnli, range_y=[0, 40_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_xnli = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    config_xnli[\"layers\"],\n",
    "    config_xnli[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_xnli.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_facebook_xnli.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layers_llama_pawsx = load_layer_to_summary(\n",
    "    data_path_pawsx, config_pawsx[\"layers\"], config_pawsx[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(df_layers_llama_pawsx, config_pawsx, range_y=[0, 40_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_pawsx = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_pawsx,\n",
    "    config_pawsx[\"layers\"],\n",
    "    config_pawsx[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_pawsx.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_google-research-datasets_paws-x.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XNLI and PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_xnli, config_xnli, df_layers_llama_pawsx, config_pawsx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_xnli,\n",
    "    config_xnli,\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLORES+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layers_llama_flores = load_layer_to_summary(\n",
    "    data_path_flores, config_flores[\"layers\"], config_flores[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(\n",
    "    df_layers_llama_flores, config_flores, range_y=[0, 40_000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_flores = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_flores,\n",
    "    config_flores[\"layers\"],\n",
    "    config_flores[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_flores.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_gsarti_flores_101.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flores-101 with XNLI and PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores, config_flores, df_layers_llama_xnli, config_xnli\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    "    df_layers_llama_xnli,\n",
    "    config_xnli,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores, config_flores, df_layers_llama_pawsx, config_pawsx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Index Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_xnli[\"model\"].split(\"/\")[-1]\n",
    "sae_model_name = config_xnli[\"sae\"][\"model\"].split(\"/\")[-1]\n",
    "\n",
    "out_path = (\n",
    "    project_dir / \"visualization\" / \"feature_index\" / model / sae_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 25\n",
    "layer = \"model.layers.0.mlp\"\n",
    "\n",
    "model = config_flores[\"model\"]\n",
    "sae_model = config_flores[\"sae\"][\"model\"]\n",
    "layers = config_flores[\"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    layer,\n",
    "    config_xnli[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "lang_to_dataset_token_activations_pawsx = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_pawsx,\n",
    "    layer,\n",
    "    config_pawsx[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "lang_to_dataset_token_activations_flores = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_flores,\n",
    "    layer,\n",
    "    config_flores[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "dataset_lang_to_dataset_token_activations = {\n",
    "    \"xnli\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_xnli,\n",
    "        \"config\": {**config_xnli},\n",
    "    },\n",
    "    \"paws-x\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_pawsx,\n",
    "        \"config\": {**config_pawsx},\n",
    "    },\n",
    "    \"flores\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_flores,\n",
    "        \"config\": {**config_flores},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_info = {\n",
    "    \"feature_index\": feature_index,\n",
    "    \"layer\": layer,\n",
    "    \"lang\": \"None\",\n",
    "    \"selected_prob\": \"-\",\n",
    "    \"entropy\": \"-\",\n",
    "    \"interpretation\": \"-\",\n",
    "    \"metrics\": [\n",
    "        {\n",
    "            \"score_type\": \"-\",\n",
    "            \"true_positives\": \"-\",\n",
    "            \"true_negatives\": \"-\",\n",
    "            \"false_positives\": \"-\",\n",
    "            \"false_negatives\": \"-\",\n",
    "            \"total_examples\": \"-\",\n",
    "            \"total_positives\": \"-\",\n",
    "            \"total_negatives\": \"-\",\n",
    "            \"failed_count\": \"-\",\n",
    "            \"precision\": \"-\",\n",
    "            \"recall\": \"-\",\n",
    "            \"f1_score\": \"-\",\n",
    "            \"accuracy\": \"-\",\n",
    "            \"true_positive_rate\": \"-\",\n",
    "            \"true_negative_rate\": \"-\",\n",
    "            \"false_positive_rate\": \"-\",\n",
    "            \"false_negative_rate\": \"-\",\n",
    "            \"positive_class_ratio\": \"-\",\n",
    "            \"negative_class_ratio\": \"-\",\n",
    "            \"auc\": None,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "generate_feature_activations_visualization(\n",
    "    dataset_lang_to_dataset_token_activations,\n",
    "    feature_index,\n",
    "    feature_info,\n",
    "    model,\n",
    "    layer,\n",
    "    sae_model,\n",
    "    out_path,\n",
    "    lang_choices_to_qualified_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_10_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_10_by_entropy.pt\"\n",
    ")\n",
    "\n",
    "lape_top_10_result = torch.load(lape_top_10_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_top_10_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_10_by_entropy\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-10 Language-Specific Features by Entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_10_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_10_by_freq.pt\"\n",
    ")\n",
    "\n",
    "lape_top_10_result = torch.load(lape_top_10_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_top_10_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_10_by_freq\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-10 Language-Specific Features by Frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_neuron_result_path = (\n",
    "    project_dir\n",
    "    / \"mlp_acts_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / \"lape_neuron.pt\"\n",
    ")\n",
    "\n",
    "lape_neuron_result = torch.load(lape_neuron_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_neuron_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/lape_neuron\"\n",
    "    ),\n",
    "    title=\"Distribution of Language-specific Neurons\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_1_per_layer_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_1_per_layer_by_entropy.pt\"\n",
    ")\n",
    "\n",
    "lape_result_top_1_per_layer = torch.load(lape_top_1_per_layer_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_result_top_1_per_layer,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_1_per_layer_by_entropy\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-1 per Layer Language-Specific Features by Entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_1_per_layer_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_1_per_layer_by_freq.pt\"\n",
    ")\n",
    "\n",
    "lape_result_top_1_per_layer = torch.load(lape_top_1_per_layer_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_result_top_1_per_layer,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_1_per_layer_by_freq\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-1 per Layer Language-Specific Features by Frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_all_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_all\"\n",
    "    ),\n",
    "    title=\"Distribution of LAPE for all Language-Specific Features\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language-Specific Features Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_metrics_to_nested_dict(df):\n",
    "    result = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        layer = row['layer']\n",
    "        latent_idx = row['latent_idx']\n",
    "        values = row.drop(['layer', 'latent_idx'])\n",
    "        values = values.apply(lambda x: round(x, 3) if isinstance(x, float) else x)\n",
    "\n",
    "        layer_key = f\"model.{layer}\"\n",
    "\n",
    "        if layer_key not in result:\n",
    "            result[layer_key] = {}\n",
    "        if latent_idx not in result[layer_key]:\n",
    "            result[layer_key][latent_idx] = []\n",
    "\n",
    "        result[layer_key][latent_idx].append(values.to_dict())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_folder = project_dir / \"interpret_sae_features\" / \"explanations\"\n",
    "\n",
    "scores_path = (\n",
    "    project_dir\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"scores\"\n",
    ")\n",
    "\n",
    "visualize_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"scores\"\n",
    ")\n",
    "\n",
    "hookpoints = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretations = load_all_interpretations(interpretation_folder)\n",
    "latent_df, counts = load_data(scores_path, hookpoints)\n",
    "df_metrics = get_metrics_per_latent(latent_df)\n",
    "metrics = convert_df_metrics_to_nested_dict(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_flores[\"model\"]\n",
    "sae_model = config_flores[\"sae\"][\"model\"]\n",
    "model_name = config_flores[\"model\"].split(\"/\")[-1]\n",
    "sae_model_name = config_flores[\"sae\"][\"model\"].split(\"/\")[-1]\n",
    "layers = config_flores[\"layers\"]\n",
    "\n",
    "sorted_lang = lape_all_result[\"sorted_lang\"]\n",
    "\n",
    "for lang in tqdm(sorted_lang, desc=\"Processing languages\"):\n",
    "    lang_index = sorted_lang.index(lang)\n",
    "\n",
    "    for layer in tqdm(layers, desc=\"Processing layers\", leave=False):\n",
    "        layer_index = layer_to_index[layer]\n",
    "        lang_final_indices = lape_all_result[\"final_indice\"][lang_index][\n",
    "            layer_index\n",
    "        ].tolist()\n",
    "\n",
    "        if len(lang_final_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        layer = layers[layer_index]\n",
    "\n",
    "        lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "            data_path_dataset_token_activations_xnli,\n",
    "            layer,\n",
    "            config_xnli[\"languages\"],\n",
    "            lang_final_indices,\n",
    "        )\n",
    "\n",
    "        lang_to_dataset_token_activations_pawsx = (\n",
    "            load_lang_to_dataset_token_activations(\n",
    "                data_path_dataset_token_activations_pawsx,\n",
    "                layer,\n",
    "                config_pawsx[\"languages\"],\n",
    "                lang_final_indices,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        lang_to_dataset_token_activations_flores = (\n",
    "            load_lang_to_dataset_token_activations(\n",
    "                data_path_dataset_token_activations_flores,\n",
    "                layer,\n",
    "                config_flores[\"languages\"],\n",
    "                lang_final_indices,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset_lang_to_dataset_token_activations = {\n",
    "            \"xnli\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_xnli,\n",
    "                \"config\": {**config_xnli},\n",
    "            },\n",
    "            \"paws-x\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_pawsx,\n",
    "                \"config\": {**config_pawsx},\n",
    "            },\n",
    "            \"flores\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_flores,\n",
    "                \"config\": {**config_flores},\n",
    "            },\n",
    "        }\n",
    "\n",
    "        out_path = (\n",
    "            project_dir\n",
    "            / \"visualization\"\n",
    "            / \"feature_index\"\n",
    "            / model_name\n",
    "            / sae_model_name\n",
    "            / layer\n",
    "            / lang\n",
    "        )\n",
    "\n",
    "        selected_probs = lape_all_result['features_info'][lang][\"selected_probs\"]\n",
    "        entropies = lape_all_result['features_info'][lang][\"entropies\"]\n",
    "        \n",
    "        for feature_index in tqdm(lang_final_indices, desc=\"Processing indices\", leave=False):\n",
    "            try:\n",
    "                file_path = out_path / f\"feature_{feature_index}.html\"\n",
    "\n",
    "                if file_path.exists():\n",
    "                    continue\n",
    "                    \n",
    "                arg_index = lape_all_result['features_info'][lang][\"indicies\"].index((layer_index, feature_index))\n",
    "\n",
    "                feature_info = {\n",
    "                    \"feature_index\": feature_index,\n",
    "                    \"layer\": layer,\n",
    "                    \"lang\": lang,\n",
    "                    \"selected_prob\": round(selected_probs[arg_index].item(), ndigits=3),\n",
    "                    \"entropy\": round(entropies[arg_index].item(), ndigits=3),\n",
    "                    \"interpretation\": interpretations[layer][feature_index],\n",
    "                    \"metrics\": metrics[layer][feature_index],\n",
    "                }\n",
    "\n",
    "                generate_feature_activations_visualization(\n",
    "                    dataset_lang_to_dataset_token_activations,\n",
    "                    feature_index,\n",
    "                    feature_info,\n",
    "                    model,\n",
    "                    layer,\n",
    "                    sae_model,\n",
    "                    out_path,\n",
    "                    lang_choices_to_qualified_name,\n",
    "                    examples_per_section=40,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {lang} - {layer} - {feature_index}\")\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_umap.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"umap\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_xnli[\"model\"]\n",
    "sae_model = config_xnli[\"sae\"][\"model\"]\n",
    "layers = config_xnli[\"layers\"]\n",
    "\n",
    "plot_umap(lape_all_result, layers, model, sae_model, umap_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ppl_output_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"normal\"\n",
    "    / \"ppl.pt\"\n",
    ")\n",
    "\n",
    "normal_ppl_result = torch.load(normal_ppl_output_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuron Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    ")\n",
    "\n",
    "intervened_neuron_ppl_results = {\n",
    "    lang_choices_to_qualified_name[intervened_lang]: torch.load(\n",
    "        out_path / f\"ppl_{intervened_lang}.pt\", weights_only=False\n",
    "    )\n",
    "    for intervened_lang in config_flores[\"languages\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    "    / \"ppl_change_matrix.html\"\n",
    ")\n",
    "\n",
    "plot_ppl_change_matrix(\n",
    "    config_flores[\"languages\"],\n",
    "    normal_ppl_result,\n",
    "    intervened_neuron_ppl_results,\n",
    "    out_path,\n",
    "    title=\"PPL Change Matrix for Neuron Interventions\",\n",
    "    num_examples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAE Feature Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"sae_intervention\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    \"top_10/entropy/max/mult_0.2\",\n",
    "    \"top_10/entropy/max/mult_-0.2\",\n",
    "    \"top_1_per_layer/entropy/avg/mult_1\",\n",
    "    \"top_1_per_layer/entropy/avg/mult_-1\",\n",
    "    \"top_1_per_layer/entropy/max/mult_0.2\",\n",
    "    \"top_1_per_layer/entropy/max/mult_-0.2\",\n",
    "    \"top_1_per_layer/freq/avg/mult_-1\",\n",
    "    \"all/entropy/max/mult_0.2\",\n",
    "    \"all/entropy/max/mult_-0.2\",\n",
    "    \"all/entropy/max/mult_-0.3\",\n",
    "    \"all/entropy/max/mult_-0.4\",\n",
    "]\n",
    "\n",
    "generate_ppl_change_matrix(\n",
    "    configs,\n",
    "    config_flores[\"model\"],\n",
    "    config_flores[\"dataset\"],\n",
    "    config_flores[\"languages\"],\n",
    "    in_path,\n",
    "    normal_ppl_result,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_path = (\n",
    "    project_dir\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"min-max\"\n",
    "    / \"metrics.json\"\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"min-max\"\n",
    ")\n",
    "\n",
    "metric = json.load(open(metric_path, \"r\"))\n",
    "\n",
    "plot_metrics(metric, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_path = (\n",
    "    project_dir\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"count\"\n",
    "    / \"metrics.json\"\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"count\"\n",
    ")\n",
    "\n",
    "metric = json.load(open(metric_path, \"r\"))\n",
    "\n",
    "plot_metrics(metric, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Combine data from both tables\n",
    "data_lower = {\n",
    "    'Language': ['de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'bg', 'ru', 'tr', 'vi', 'ja', 'ko', 'zh'],\n",
    "    'Alpha': [0.4, 0.3, 0.4, 0.2, 0.175, 0.5, 0.375, 0.4, 0.5, 0.25, 0.3, 0.3, 0.4, 0.3],\n",
    "    'Change_Count': [17, 29, 10, 17, 29, 42, 18, 8, 27, 16, 11, 9, 16, 28],\n",
    "    'Change_Incoherent': [0, 0, 3, 0, 19, 0, 6, 0, 2, 1, 0, 4, 4, 1],\n",
    "    'Change_Partially_Coherent': [3, 15, 4, 7, 7, 10, 12, 5, 15, 13, 7, 3, 11, 12],\n",
    "    'Change_Coherent': [14, 14, 3, 10, 3, 32, 0, 3, 10, 2, 4, 2, 1, 15],\n",
    "    'Unchange_Count': [83, 71, 90, 83, 71, 58, 82, 92, 73, 84, 89, 91, 84, 72],\n",
    "    'Unchange_Incoherent': [2, 0, 0, 5, 2, 0, 0, 1, 2, 0, 2, 6, 3, 1],\n",
    "    'Unchange_Partially_Coherent': [7, 0, 8, 16, 3, 3, 11, 30, 4, 17, 7, 10, 18, 3],\n",
    "    'Unchange_Coherent': [74, 71, 82, 62, 64, 55, 71, 61, 67, 67, 80, 75, 63, 68]\n",
    "}\n",
    "\n",
    "data_higher = {\n",
    "    'Language': ['en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'bg', 'ru', 'tr', 'vi', 'ja', 'ko', 'zh'],\n",
    "    'Alpha': [-1.2, 0.5, 0.4, 0.5, 0.25, 0.2, 0.8, 0.4, 0.5, 0.6, 0.3, 0.4, 0.4, 0.5, 0.4],\n",
    "    'Change_Count': [5, 27, 38, 23, 12, 30, 45, 45, 22, 34, 27, 18, 19, 43, 66],\n",
    "    'Change_Incoherent': [1, 2, 14, 20, 3, 23, 1, 37, 12, 9, 11, 4, 8, 24, 7],\n",
    "    'Change_Partially_Coherent': [3, 13, 14, 3, 7, 5, 26, 8, 10, 12, 11, 9, 10, 18, 32],\n",
    "    'Change_Coherent': [1, 12, 10, 0, 2, 2, 18, 0, 0, 13, 5, 5, 1, 1, 27],\n",
    "    'Unchange_Count': [95, 73, 62, 77, 88, 70, 55, 55, 78, 66, 73, 82, 81, 57, 34],\n",
    "    'Unchange_Incoherent': [8, 3, 1, 2, 28, 9, 0, 2, 3, 15, 6, 11, 9, 6, 1],\n",
    "    'Unchange_Partially_Coherent': [10, 15, 0, 4, 17, 3, 1, 11, 32, 5, 8, 12, 10, 8, 2],\n",
    "    'Unchange_Coherent': [77, 55, 61, 71, 43, 58, 54, 41, 43, 46, 59, 59, 62, 43, 31]\n",
    "}\n",
    "\n",
    "# Combine both datasets\n",
    "df_lower = pd.DataFrame(data_lower)\n",
    "df_lower['Table'] = 'Lower α'\n",
    "\n",
    "df_higher = pd.DataFrame(data_higher)\n",
    "df_higher['Table'] = 'Higher α'\n",
    "\n",
    "# Remove English from higher as it's a special case with negative alpha\n",
    "df_higher_no_en = df_higher[df_higher['Language'] != 'en'].copy()\n",
    "\n",
    "# Combine dataframes\n",
    "df_combined = pd.concat([df_lower, df_higher_no_en])\n",
    "\n",
    "# Find languages that appear in both tables\n",
    "common_languages = set(df_lower['Language']).intersection(set(df_higher_no_en['Language']))\n",
    "\n",
    "# Create a dataframe with paired data for languages that appear in both tables\n",
    "paired_data = []\n",
    "for lang in common_languages:\n",
    "    lower_row = df_lower[df_lower['Language'] == lang].iloc[0]\n",
    "    higher_row = df_higher_no_en[df_higher_no_en['Language'] == lang].iloc[0]\n",
    "    \n",
    "    paired_data.append({\n",
    "        'Language': lang,\n",
    "        'Alpha_Lower': lower_row['Alpha'],\n",
    "        'Alpha_Higher': higher_row['Alpha'],\n",
    "        'Change_Count_Lower': lower_row['Change_Count'],\n",
    "        'Change_Count_Higher': higher_row['Change_Count'],\n",
    "        'Change_Incoherent_Lower': lower_row['Change_Incoherent'],\n",
    "        'Change_Incoherent_Higher': higher_row['Change_Incoherent'],\n",
    "        'Change_Partially_Coherent_Lower': lower_row['Change_Partially_Coherent'],\n",
    "        'Change_Partially_Coherent_Higher': higher_row['Change_Partially_Coherent'],\n",
    "        'Change_Coherent_Lower': lower_row['Change_Coherent'],\n",
    "        'Change_Coherent_Higher': higher_row['Change_Coherent']\n",
    "    })\n",
    "\n",
    "df_paired = pd.DataFrame(paired_data)\n",
    "\n",
    "# Calculate percentages of coherence categories within the Changed texts\n",
    "df_paired['Change_Incoherent_Pct_Lower'] = df_paired['Change_Incoherent_Lower'] / df_paired['Change_Count_Lower'] * 100\n",
    "df_paired['Change_Partially_Coherent_Pct_Lower'] = df_paired['Change_Partially_Coherent_Lower'] / df_paired['Change_Count_Lower'] * 100\n",
    "df_paired['Change_Coherent_Pct_Lower'] = df_paired['Change_Coherent_Lower'] / df_paired['Change_Count_Lower'] * 100\n",
    "\n",
    "df_paired['Change_Incoherent_Pct_Higher'] = df_paired['Change_Incoherent_Higher'] / df_paired['Change_Count_Higher'] * 100\n",
    "df_paired['Change_Partially_Coherent_Pct_Higher'] = df_paired['Change_Partially_Coherent_Higher'] / df_paired['Change_Count_Higher'] * 100\n",
    "df_paired['Change_Coherent_Pct_Higher'] = df_paired['Change_Coherent_Higher'] / df_paired['Change_Count_Higher'] * 100\n",
    "\n",
    "# Sort by alpha difference to see the effect of increasing alpha\n",
    "df_paired['Alpha_Diff'] = df_paired['Alpha_Higher'] - df_paired['Alpha_Lower']\n",
    "df_paired = df_paired.sort_values(by='Alpha_Diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ordered language list\n",
    "ordered_languages = [\n",
    "    \"de\",\n",
    "    \"fr\",\n",
    "    \"it\",\n",
    "    \"pt\",\n",
    "    \"hi\",\n",
    "    \"es\",\n",
    "    \"th\",\n",
    "    \"bg\",\n",
    "    \"ru\",\n",
    "    \"tr\",\n",
    "    \"vi\",\n",
    "    \"ja\",\n",
    "    \"ko\",\n",
    "    \"zh\",\n",
    "]\n",
    "\n",
    "# Sort the paired dataframe according to the ordered language list\n",
    "df_paired[\"Language_Order\"] = df_paired[\"Language\"].apply(\n",
    "    lambda x: (\n",
    "        ordered_languages.index(x) if x in ordered_languages else len(ordered_languages)\n",
    "    )\n",
    ")\n",
    "df_paired = df_paired.sort_values(\"Language_Order\").reset_index(drop=True)\n",
    "\n",
    "# Figure 1: Comparing change in language generation at different alpha values\n",
    "fig1 = go.Figure()\n",
    "\n",
    "# Add lines for each coherence category\n",
    "fig1.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_paired[\"Language\"],\n",
    "        y=df_paired[\"Change_Count_Lower\"],\n",
    "        mode=\"markers+lines\",\n",
    "        name=\"Changed Text Count (Lower α)\",\n",
    "        marker=dict(size=10, color=\"blue\"),\n",
    "        line=dict(width=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig1.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_paired[\"Language\"],\n",
    "        y=df_paired[\"Change_Count_Higher\"],\n",
    "        mode=\"markers+lines\",\n",
    "        name=\"Changed Text Count (Higher α)\",\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        line=dict(width=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add alpha values as annotations\n",
    "for i, row in df_paired.iterrows():\n",
    "    fig1.add_annotation(\n",
    "        x=row[\"Language\"],\n",
    "        y=row[\"Change_Count_Lower\"],\n",
    "        text=f\"α={row['Alpha_Lower']}\",\n",
    "        showarrow=False,\n",
    "        yshift=-20,\n",
    "        font=dict(size=10, color=\"blue\"),\n",
    "    )\n",
    "    fig1.add_annotation(\n",
    "        x=row[\"Language\"],\n",
    "        y=row[\"Change_Count_Higher\"],\n",
    "        text=f\"α={row['Alpha_Higher']}\",\n",
    "        showarrow=False,\n",
    "        yshift=10,\n",
    "        font=dict(size=10, color=\"red\"),\n",
    "    )\n",
    "\n",
    "fig1.update_layout(\n",
    "    title=\"Impact of Increasing Scaling Factor (α) on Language Generation\",\n",
    "    xaxis_title=\"Target Language\",\n",
    "    yaxis_title=\"Count of Texts Changed to Target Language\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    hovermode=\"x unified\",\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "fig1.update_xaxes(\n",
    "    categoryorder=\"array\",\n",
    "    categoryarray=ordered_languages,\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig1.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig1.write_image(\n",
    "    output_path / \"impact_of_increasing_scaling_factor_on_language_generation.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Coherence breakdown as stacked bars\n",
    "fig2 = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Lower α Values', 'Higher α Values'),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Convert dataframe to long format for easier plotting\n",
    "coherence_data = []\n",
    "for i, row in df_paired.iterrows():\n",
    "    # Lower alpha values\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Lower',\n",
    "        'Alpha': row['Alpha_Lower'],\n",
    "        'Category': 'Coherent', \n",
    "        'Percentage': row['Change_Coherent_Pct_Lower']\n",
    "    })\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Lower',\n",
    "        'Alpha': row['Alpha_Lower'],\n",
    "        'Category': 'Partially Coherent', \n",
    "        'Percentage': row['Change_Partially_Coherent_Pct_Lower']\n",
    "    })\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Lower',\n",
    "        'Alpha': row['Alpha_Lower'],\n",
    "        'Category': 'Incoherent', \n",
    "        'Percentage': row['Change_Incoherent_Pct_Lower']\n",
    "    })\n",
    "    \n",
    "    # Higher alpha values\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Higher',\n",
    "        'Alpha': row['Alpha_Higher'],\n",
    "        'Category': 'Coherent', \n",
    "        'Percentage': row['Change_Coherent_Pct_Higher']\n",
    "    })\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Higher',\n",
    "        'Alpha': row['Alpha_Higher'],\n",
    "        'Category': 'Partially Coherent', \n",
    "        'Percentage': row['Change_Partially_Coherent_Pct_Higher']\n",
    "    })\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Higher',\n",
    "        'Alpha': row['Alpha_Higher'],\n",
    "        'Category': 'Incoherent', \n",
    "        'Percentage': row['Change_Incoherent_Pct_Higher']\n",
    "    })\n",
    "\n",
    "df_coherence = pd.DataFrame(coherence_data)\n",
    "\n",
    "\n",
    "# Create color map for coherence categories\n",
    "color_map = {\n",
    "    'Coherent': 'rgb(53, 167, 107)',\n",
    "    'Partially Coherent': 'rgb(253, 174, 97)',\n",
    "    'Incoherent': 'rgb(215, 48, 39)'\n",
    "}\n",
    "\n",
    "# Plot lower alpha coherence breakdown\n",
    "for category in ['Coherent', 'Partially Coherent', 'Incoherent']:\n",
    "    df_cat = df_coherence[(df_coherence['Alpha Value'] == 'Lower') & \n",
    "                          (df_coherence['Category'] == category)]\n",
    "    \n",
    "    # Reorder data according to language_order\n",
    "    df_cat = df_cat.set_index('Language').reindex(ordered_languages).reset_index()\n",
    "    \n",
    "    fig2.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_cat['Language'],\n",
    "            y=df_cat['Percentage'],\n",
    "            name=category,\n",
    "            marker_color=color_map[category],\n",
    "            legendgroup=category,\n",
    "            showlegend=True,\n",
    "            text=[f\"{val:.1f}%\" for val in df_cat['Percentage']],\n",
    "            textposition='inside',\n",
    "            textfont=dict(color='white', size=10),\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Plot higher alpha coherence breakdown\n",
    "for category in ['Coherent', 'Partially Coherent', 'Incoherent']:\n",
    "    df_cat = df_coherence[(df_coherence['Alpha Value'] == 'Higher') & \n",
    "                          (df_coherence['Category'] == category)]\n",
    "    \n",
    "    # Reorder data according to language_order\n",
    "    df_cat = df_cat.set_index('Language').reindex(ordered_languages).reset_index()\n",
    "    \n",
    "    fig2.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_cat['Language'],\n",
    "            y=df_cat['Percentage'],\n",
    "            name=category,\n",
    "            marker_color=color_map[category],\n",
    "            legendgroup=category,\n",
    "            showlegend=False,\n",
    "            text=[f\"{val:.1f}%\" for val in df_cat['Percentage']],\n",
    "            textposition='inside',\n",
    "            textfont=dict(color='white', size=10),\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Add alpha values as annotations on x-axis\n",
    "for col, alpha_val in enumerate(['Lower', 'Higher'], 1):\n",
    "    for i, lang in enumerate(ordered_languages):\n",
    "        alpha = df_paired[df_paired['Language'] == lang][f'Alpha_{alpha_val}'].values[0]\n",
    "        fig2.add_annotation(\n",
    "            x=lang,\n",
    "            y=-10,\n",
    "            text=f\"α={alpha}\",\n",
    "            showarrow=False,\n",
    "            xref=f'x{col}',\n",
    "            yref=f'y{col}',\n",
    "            font=dict(size=10)\n",
    "        )\n",
    "\n",
    "fig2.update_layout(\n",
    "    title='Impact of Scaling Factor (α) on Text Coherence in Changed Languages',\n",
    "    barmode='stack',\n",
    "    legend=dict(orientation=\"h\", yanchor=\"top\", y=1.115, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    yaxis=dict(title='Percentage (%)', range=[0, 100]),\n",
    "    yaxis2=dict(title='Percentage (%)', range=[0, 100]),\n",
    "    xaxis=dict(title='Target Language'),\n",
    "    xaxis2=dict(title='Target Language')\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig2.write_image(\n",
    "    output_path / \"impact_of_scaling_factor_on_text_coherence_changed.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# (Assumes df_lower, df_higher_no_en and df_paired already exist as in your setup)\n",
    "\n",
    "# 1) Build Figure 2b\n",
    "fig2b = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Lower α Values\", \"Higher α Values\"),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n",
    ")\n",
    "\n",
    "# 2) Collect “unchanged” coherence data, but normalize over the sum of the three categories\n",
    "unchanged_coherence_data = []\n",
    "for _, row in df_paired.iterrows():\n",
    "    lang = row[\"Language\"]\n",
    "    lower = df_lower.loc[df_lower[\"Language\"] == lang].iloc[0]\n",
    "    higher = df_higher_no_en.loc[df_higher_no_en[\"Language\"] == lang].iloc[0]\n",
    "\n",
    "    # Lower α\n",
    "    total_lower = (\n",
    "        lower[\"Unchange_Coherent\"]\n",
    "        + lower[\"Unchange_Partially_Coherent\"]\n",
    "        + lower[\"Unchange_Incoherent\"]\n",
    "    )\n",
    "    if total_lower > 0:\n",
    "        unchanged_coherence_data += [\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Coherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Coherent\"] / total_lower * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Partially Coherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Partially_Coherent\"] / total_lower * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Incoherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Incoherent\"] / total_lower * 100,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "    # Higher α\n",
    "    total_higher = (\n",
    "        higher[\"Unchange_Coherent\"]\n",
    "        + higher[\"Unchange_Partially_Coherent\"]\n",
    "        + higher[\"Unchange_Incoherent\"]\n",
    "    )\n",
    "    if total_higher > 0:\n",
    "        unchanged_coherence_data += [\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Coherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Coherent\"] / total_higher * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Partially Coherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Partially_Coherent\"]\n",
    "                / total_higher\n",
    "                * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Incoherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Incoherent\"] / total_higher * 100,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "df_unchanged_coherence = pd.DataFrame(unchanged_coherence_data)\n",
    "\n",
    "# 3) Plot it\n",
    "color_map = {\n",
    "    \"Coherent\": \"rgb(53, 167, 107)\",\n",
    "    \"Partially Coherent\": \"rgb(253, 174, 97)\",\n",
    "    \"Incoherent\": \"rgb(215, 48, 39)\",\n",
    "}\n",
    "language_order = df_paired[\"Language\"].tolist()\n",
    "\n",
    "for col, alpha_val in enumerate([\"Lower\", \"Higher\"], start=1):\n",
    "    for category in [\"Coherent\", \"Partially Coherent\", \"Incoherent\"]:\n",
    "        df_cat = (\n",
    "            df_unchanged_coherence.query(\n",
    "                \"`Alpha Value` == @alpha_val and Category == @category\"\n",
    "            )\n",
    "            .set_index(\"Language\")\n",
    "            .reindex(language_order)\n",
    "            .reset_index()\n",
    "        )\n",
    "        fig2b.add_trace(\n",
    "            go.Bar(\n",
    "                x=df_cat[\"Language\"],\n",
    "                y=df_cat[\"Percentage\"],\n",
    "                name=category,\n",
    "                marker_color=color_map[category],\n",
    "                legendgroup=category,\n",
    "                showlegend=(col == 1),  # only show legend in first subplot\n",
    "                text=[f\"{v:.1f}%\" for v in df_cat[\"Percentage\"]],\n",
    "                textposition=\"inside\",\n",
    "                textfont=dict(color=\"white\", size=10),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "    # add α annotation under each language tick\n",
    "    for lang in language_order:\n",
    "        α = (\n",
    "            row[f\"Alpha_{alpha_val}\"]\n",
    "            if False\n",
    "            else df_paired.loc[\n",
    "                df_paired[\"Language\"] == lang, f\"Alpha_{alpha_val}\"\n",
    "            ].iloc[0]\n",
    "        )\n",
    "        fig2b.add_annotation(\n",
    "            x=lang,\n",
    "            y=-5,\n",
    "            text=f\"α={α}\",\n",
    "            showarrow=False,\n",
    "            xref=f\"x{col}\",\n",
    "            yref=f\"y{col}\",\n",
    "            font=dict(size=10),\n",
    "        )\n",
    "\n",
    "fig2b.update_layout(\n",
    "    title=\"Impact of Scaling Factor (α) on Text Coherence in Unchanged Languages\",\n",
    "    barmode=\"stack\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"top\", y=1.115, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    yaxis=dict(title=\"Percentage (%)\", range=[0, 100]),\n",
    "    yaxis2=dict(title=\"Percentage (%)\", range=[0, 100]),\n",
    "    xaxis=dict(title=\"Target Language\"),\n",
    "    xaxis2=dict(title=\"Target Language\"),\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig2b.write_image(\n",
    "    output_path / \"impact_of_scaling_factor_on_text_coherence_unchanged.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language-specific features Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_folder = project_dir / \"interpret_sae_features\" / \"explanations\"\n",
    "scores_path = (\n",
    "    project_dir\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"scores\"\n",
    ")\n",
    "\n",
    "visualize_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"scores\"\n",
    ")\n",
    "\n",
    "hookpoints = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]\n",
    "\n",
    "interpretations = load_all_interpretations(interpretation_folder)\n",
    "latent_df, counts = load_data(scores_path, hookpoints)\n",
    "df_metrics = get_metrics_per_latent(latent_df)\n",
    "metrics = convert_df_metrics_to_nested_dict(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_result(lape_result, df_metrics):\n",
    "    score_results = {}\n",
    "\n",
    "    sorted_lang = lape_result[\"sorted_lang\"]\n",
    "\n",
    "    for lang_idx, lang in enumerate(sorted_lang):\n",
    "        lang_final_indices = lape_result[\"final_indice\"][lang_idx]\n",
    "\n",
    "        combined_df = None\n",
    "\n",
    "        for layer_idx, _ in enumerate(lang_final_indices):\n",
    "            lang_layer_final_indices = lang_final_indices[layer_idx].tolist()\n",
    "            layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "\n",
    "            combined_df = pd.concat(\n",
    "                [\n",
    "                    combined_df,\n",
    "                    df_metrics.query(\n",
    "                        \"layer == @layer_str and latent_idx in @lang_layer_final_indices\"\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        score_results[lang] = (\n",
    "            combined_df.groupby(\"score_type\")[[\"precision\", \"recall\", \"f1_score\"]]\n",
    "            .mean()\n",
    "            .to_dict(orient=\"index\")\n",
    "        )\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for lang, score_types in score_results.items():\n",
    "        for score_type, metrics in score_types.items():\n",
    "            row = {\"Language\": lang, \"Score Type\": score_type}\n",
    "            row.update(metrics)\n",
    "            rows.append(row)\n",
    "\n",
    "    df_scores = pd.DataFrame(rows)\n",
    "    df_scores[[\"precision\", \"recall\", \"f1_score\"]] = df_scores[\n",
    "        [\"precision\", \"recall\", \"f1_score\"]\n",
    "    ].round(3)\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score_result(lape_all_result, df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features similarity (IoU and Pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"similarity\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    ")\n",
    "\n",
    "task_configs = {\n",
    "    \"xnli\": {\n",
    "        \"path\": data_path_dataset_token_activations_xnli,\n",
    "        \"config\": config_xnli,\n",
    "    },\n",
    "    \"paws-x\": {\n",
    "        \"path\": data_path_dataset_token_activations_pawsx,\n",
    "        \"config\": config_pawsx,\n",
    "    },\n",
    "    \"flores\": {\n",
    "        \"path\": data_path_dataset_token_activations_flores,\n",
    "        \"config\": config_flores,\n",
    "    },\n",
    "}\n",
    "\n",
    "plot_features_similarity(\n",
    "    lape_all_result,\n",
    "    config_flores[\"layers\"],\n",
    "    output_dir,\n",
    "    task_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine Similarity of Language-Specific Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lang = lape_all_result[\"sorted_lang\"]\n",
    "\n",
    "lang_to_sae_features = {\n",
    "    lang: {\n",
    "        \"final_indices\": [],\n",
    "        \"stacked_sae_features\": [],\n",
    "    }\n",
    "    for lang in sorted_lang\n",
    "}\n",
    "\n",
    "\n",
    "for lang_idx, lang in enumerate(sorted_lang):\n",
    "    lang_final_indices = lape_all_result[\"final_indice\"][lang_idx]\n",
    "    lang_sae_features = lape_all_result[\"sae_features\"][lang_idx]\n",
    "\n",
    "    lang_to_sae_features[lang][\"final_indices\"] = [indices.tolist() for indices in lang_final_indices]\n",
    "    lang_to_sae_features[lang][\"stacked_sae_features\"] = [features.tolist() for features in lang_sae_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Collect all features and create language boundaries\n",
    "all_features = []\n",
    "all_feature_indices = []\n",
    "all_layer_numbers = []\n",
    "language_boundaries = []\n",
    "current_position = 0\n",
    "lang_names_for_features = []\n",
    "\n",
    "# Stack all features from all languages\n",
    "for lang in sorted_lang:\n",
    "    lang_features = lang_to_sae_features[lang][\"stacked_sae_features\"]\n",
    "    lang_indices = lang_to_sae_features[lang][\"final_indices\"]\n",
    "\n",
    "    # Each element in stacked_sae_features corresponds to a layer/position\n",
    "    # and contains feature vectors for the indices found at that position\n",
    "    for layer_idx, feature_vectors in enumerate(lang_features):\n",
    "        layer_indices = lang_indices[\n",
    "            layer_idx\n",
    "        ]  # Get corresponding indices for this layer\n",
    "\n",
    "        # feature_vectors is a list of feature vectors for this layer\n",
    "        for feat_idx, feature_vector in enumerate(feature_vectors):\n",
    "            all_features.append(feature_vector)\n",
    "            # Get the actual feature index from final_indices\n",
    "            if feat_idx < len(layer_indices):\n",
    "                actual_index = layer_indices[feat_idx]\n",
    "            else:\n",
    "                actual_index = f\"unknown_{current_position}\"\n",
    "            all_feature_indices.append(actual_index)\n",
    "            all_layer_numbers.append(layer_idx)  # Store the layer number\n",
    "            lang_names_for_features.append(lang)\n",
    "            current_position += 1\n",
    "\n",
    "    # Mark the boundary after this language\n",
    "    language_boundaries.append(current_position)\n",
    "\n",
    "# Convert to numpy array for cosine similarity calculation\n",
    "features_array = np.array(all_features)\n",
    "print(f\"Feature array shape: {features_array.shape}\")\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(features_array)\n",
    "\n",
    "# Create the heatmap\n",
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=similarity_matrix,\n",
    "        colorscale=\"RdBu\",\n",
    "        zmid=0,  # Center the colorscale at 0\n",
    "        colorbar=dict(\n",
    "            title=\"Cosine Similarity\",\n",
    "        ),\n",
    "        hovertemplate=\"Lang: %{customdata[0]}<br>Layer: %{customdata[1]}, Index: %{customdata[2]}<br>Lang: %{customdata[3]}<br>Layer: %{customdata[4]}, Index: %{customdata[5]}<br>Similarity: %{z:.3f}<extra></extra>\",\n",
    "        customdata=np.array(\n",
    "            [\n",
    "                [\n",
    "                    lang_names_for_features[i],\n",
    "                    all_layer_numbers[i],\n",
    "                    all_feature_indices[i],\n",
    "                    lang_names_for_features[j],\n",
    "                    all_layer_numbers[j],\n",
    "                    all_feature_indices[j],\n",
    "                ]\n",
    "                for i in range(len(all_feature_indices))\n",
    "                for j in range(len(all_feature_indices))\n",
    "            ]\n",
    "        ).reshape(len(all_feature_indices), len(all_feature_indices), 6),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add language boundaries as lines\n",
    "boundary_color = \"black\"\n",
    "boundary_width = 2\n",
    "\n",
    "# Add vertical lines for language boundaries\n",
    "for boundary in language_boundaries[:-1]:  # Exclude the last boundary (end of data)\n",
    "    fig.add_vline(\n",
    "        x=boundary - 0.5,\n",
    "        line=dict(color=boundary_color, width=boundary_width),\n",
    "        layer=\"above\",\n",
    "    )\n",
    "\n",
    "# Add horizontal lines for language boundaries\n",
    "for boundary in language_boundaries[:-1]:\n",
    "    fig.add_hline(\n",
    "        y=boundary - 0.5,\n",
    "        line=dict(color=boundary_color, width=boundary_width),\n",
    "        layer=\"above\",\n",
    "    )\n",
    "\n",
    "# Create language labels for the plot\n",
    "lang_positions = []\n",
    "lang_labels = []\n",
    "prev_boundary = 0\n",
    "\n",
    "for i, (lang, boundary) in enumerate(zip(sorted_lang, language_boundaries)):\n",
    "    # Calculate the middle position for each language section\n",
    "    middle_pos = (prev_boundary + boundary) / 2\n",
    "    lang_positions.append(middle_pos)\n",
    "    lang_labels.append(lang)\n",
    "    prev_boundary = boundary\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        \"text\": \"Cosine Similarity Heatmap of Language-Specific Features\",\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"font\": {\"size\": 16},\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title=\"Feature Index\",\n",
    "        tickfont=dict(size=6),\n",
    "        # Add language labels at appropriate positions\n",
    "        tickmode=\"array\",\n",
    "        tickvals=lang_positions,\n",
    "        ticktext=lang_labels,\n",
    "        tickangle=45,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Feature Index\",\n",
    "        tickfont=dict(size=6),\n",
    "        # Add language labels at appropriate positions\n",
    "        tickmode=\"array\",\n",
    "        tickvals=lang_positions,\n",
    "        ticktext=lang_labels,\n",
    "        autorange=\"reversed\",  # Reverse y-axis to match typical matrix visualization\n",
    "    ),\n",
    "    # width=800,\n",
    "    height=1000,\n",
    "    font=dict(size=10),\n",
    ")\n",
    "\n",
    "# Add annotations for language boundaries\n",
    "annotations = []\n",
    "for i, lang in enumerate(sorted_lang):\n",
    "    # Add language labels on the diagonal\n",
    "    pos = lang_positions[i]\n",
    "    annotations.append(\n",
    "        dict(\n",
    "            x=pos,\n",
    "            y=pos,\n",
    "            text=lang,\n",
    "            showarrow=False,\n",
    "            font=dict(color=\"white\", size=8, family=\"Arial Black\"),\n",
    "            bgcolor=\"rgba(0,0,0,0.7)\",\n",
    "            bordercolor=\"white\",\n",
    "            borderwidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(annotations=annotations)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Optional: Print some statistics\n",
    "print(f\"\\nSimilarity Matrix Statistics:\")\n",
    "print(f\"Shape: {similarity_matrix.shape}\")\n",
    "print(f\"Min similarity: {similarity_matrix.min():.3f}\")\n",
    "print(f\"Max similarity: {similarity_matrix.max():.3f}\")\n",
    "print(f\"Mean similarity: {similarity_matrix.mean():.3f}\")\n",
    "\n",
    "# Print language boundaries for reference\n",
    "print(f\"\\nLanguage boundaries:\")\n",
    "for i, (lang, boundary) in enumerate(zip(sorted_lang, language_boundaries)):\n",
    "    start = language_boundaries[i - 1] if i > 0 else 0\n",
    "    feature_count = boundary - start\n",
    "    print(f\"{lang}: features {start} to {boundary-1} (total: {feature_count} features)\")\n",
    "\n",
    "    # Show some example feature indices and layers for this language\n",
    "    lang_feature_indices = all_feature_indices[start:boundary]\n",
    "    lang_layer_numbers = all_layer_numbers[start:boundary]\n",
    "    examples = [\n",
    "        (layer, idx)\n",
    "        for layer, idx in zip(lang_layer_numbers[:5], lang_feature_indices[:5])\n",
    "    ]\n",
    "    print(f\"  Example (layer, index): {examples}{'...' if feature_count > 5 else ''}\")\n",
    "\n",
    "# Print total feature count\n",
    "print(f\"\\nTotal features collected: {len(all_features)}\")\n",
    "print(f\"Languages: {len(sorted_lang)}\")\n",
    "print(\n",
    "    f\"Feature indices range: {min(all_feature_indices)} to {max(all_feature_indices)}\"\n",
    ")\n",
    "print(f\"Layer numbers range: {min(all_layer_numbers)} to {max(all_layer_numbers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparsify import Sae\n",
    "\n",
    "sae_vectors = {}\n",
    "\n",
    "layers = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]\n",
    "\n",
    "for layer in layers:\n",
    "    sae = Sae.load_from_hub(\"EleutherAI/sae-Llama-3.2-1B-131k\", hookpoint=layer)\n",
    "\n",
    "    sae_vectors[layer] = {\n",
    "        \"bias\": sae.b_dec.detach(),\n",
    "    }\n",
    "\n",
    "    del sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang, layer_final_indices in lang_to_sae_features.items():\n",
    "    for layer_idx, final_indices in enumerate(layer_final_indices[\"final_indices\"]):\n",
    "        layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "        bias_vector = sae_vectors[layer_str][\"bias\"]\n",
    "\n",
    "        # Get the feature vectors for this language and layer\n",
    "        feature_vectors = layer_final_indices[\"stacked_sae_features\"][layer_idx]\n",
    "        lang_layer_feature_indices = layer_final_indices[\"final_indices\"][layer_idx]\n",
    "\n",
    "        if len(feature_vectors) == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate cosine similarity between bias vector and feature vectors\n",
    "        similarity_scores = cosine_similarity(bias_vector.unsqueeze(0), feature_vectors)\n",
    "\n",
    "        # Print or store the similarity scores as needed\n",
    "        print(\n",
    "            f\"Language: {lang}, Layer: {layer_str}, indicies:{lang_layer_feature_indices}, Similarity Scores: {similarity_scores}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 10 Tokens of Features x W_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "llm = LanguageModel(\"meta-llama/Llama-3.2-1B\", device_map=\"cpu\", dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang, layer_final_indices in lang_to_sae_features.items():\n",
    "    print(f\"Language: {lang}\")\n",
    "    for layer_idx, final_indices in enumerate(layer_final_indices[\"final_indices\"]):\n",
    "        layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "        bias_vector = sae_vectors[layer_str][\"bias\"]\n",
    "\n",
    "        # Get the feature vectors for this language and layer\n",
    "        feature_vectors = layer_final_indices[\"stacked_sae_features\"][layer_idx]\n",
    "\n",
    "        if len(feature_vectors) == 0:\n",
    "            continue\n",
    "\n",
    "        # Feed the feature vectors through the lm_head to get token logits\n",
    "        with torch.no_grad():\n",
    "            norm = llm.model.norm(torch.tensor(feature_vectors))\n",
    "            logits = llm.lm_head(norm)\n",
    "\n",
    "        # Get the top 20 tokens for each feature vector\n",
    "        top_token_indices = torch.topk(logits, 10, dim=-1).indices\n",
    "\n",
    "        # Print the language, layer, and top tokens for each feature\n",
    "        for i, feature_idx in enumerate(feature_vectors):\n",
    "            top_tokens = top_token_indices[i].tolist()\n",
    "            token_strings = [llm.tokenizer.decode([idx]) for idx in top_tokens]\n",
    "            token_display = \", \".join([f\"{token}\" for token in token_strings])\n",
    "            print(f\"Layer: {layer_str}\")\n",
    "            print(f\"  Top tokens: {token_display}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang, layer_final_indices in lang_to_sae_features.items():\n",
    "    print(f\"Language: {lang}\")\n",
    "    for layer_idx, final_indices in enumerate(layer_final_indices[\"final_indices\"]):\n",
    "        layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "        bias_vector = sae_vectors[layer_str][\"bias\"]\n",
    "\n",
    "        # Get the feature vectors for this language and layer\n",
    "        feature_vectors = layer_final_indices[\"stacked_sae_features\"][layer_idx]\n",
    "\n",
    "        if len(feature_vectors) == 0:\n",
    "            continue\n",
    "\n",
    "        # Feed the feature vectors through the lm_head to get token logits\n",
    "        with torch.no_grad():\n",
    "            norm = llm.model.norm(torch.tensor(feature_vectors).sum(dim=0))\n",
    "            logits = llm.lm_head(norm)\n",
    "\n",
    "        # Get the top 20 tokens for each feature vector\n",
    "        top_token_indices = torch.topk(logits, 10, dim=-1).indices\n",
    "\n",
    "        # Print the language, layer, and top tokens for each feature\n",
    "        top_tokens = top_token_indices.tolist()\n",
    "        token_strings = [llm.tokenizer.decode([idx]) for idx in top_tokens]\n",
    "        token_display = \", \".join([f\"{token}\" for token in token_strings])\n",
    "        print(f\"Layer: {layer_str}\")\n",
    "        print(f\"  Top tokens: {token_display}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropies and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_features_info = load_sae_features_info_df(\n",
    "    lape_all_result,\n",
    "    config_flores[\"layers\"],\n",
    "    metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"correlation\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]   \n",
    ")\n",
    "\n",
    "plot_sae_features_entropy_score_correlation(\n",
    "    sae_features_info,\n",
    "    output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Language-Specific Features Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_sae_features_info = load_lang_to_sae_features_info(\n",
    "    lape_all_result,\n",
    "    config_flores[\"layers\"],\n",
    "    interpretations,\n",
    "    metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = (\n",
    "    project_dir\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"language_specific_features\"\n",
    ")\n",
    "\n",
    "with open(output_dir / \"lang_to_sae_features_info.json\", \"w\") as f:\n",
    "    json.dump(lang_to_sae_features_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_sae_features_info_extra = load_lang_to_sae_features_info(\n",
    "    lape_all_result,\n",
    "    config_flores[\"layers\"],\n",
    "    interpretations,\n",
    "    metrics,\n",
    "    extra=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = (\n",
    "    project_dir\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"language_specific_features\"\n",
    ")\n",
    "\n",
    "with open(output_dir / \"lang_to_sae_features_info_extra.json\", \"w\") as f:\n",
    "    json.dump(lang_to_sae_features_info_extra, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook(output_dir / \"lang_to_sae_features_info_extra.xlsx\")\n",
    "\n",
    "# Define cell formats\n",
    "header_format = workbook.add_format(\n",
    "    {\n",
    "        \"bold\": True,\n",
    "        \"text_wrap\": True,\n",
    "        \"valign\": \"vcenter\",\n",
    "        \"align\": \"center\",\n",
    "        \"border\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "center_aligned_format = workbook.add_format(\n",
    "    {\n",
    "        \"align\": \"center\",\n",
    "        \"valign\": \"vcenter\",\n",
    "        \"border\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "left_wrap_format = workbook.add_format(\n",
    "    {\n",
    "        \"align\": \"left\",\n",
    "        \"valign\": \"vcenter\",\n",
    "        \"text_wrap\": True,\n",
    "        \"border\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Iterate over each language in the JSON data\n",
    "for lang_name, layers_data in lang_to_sae_features_info_extra.items():\n",
    "    # Add a new worksheet for each language. Sheet names have a max length of 31.\n",
    "    worksheet_name = lang_name if len(lang_name) < 32 else lang_name[:31]\n",
    "    worksheet = workbook.add_worksheet(worksheet_name)\n",
    "\n",
    "    # Set column widths\n",
    "    worksheet.set_column(\"A:A\", 17.56)  # Layer\n",
    "    worksheet.set_column(\"B:B\", 8.67)  # Lang\n",
    "    worksheet.set_column(\"C:C\", 11.89)  # Feature ID\n",
    "    worksheet.set_column(\"D:D\", 52.22)  # Interpretation\n",
    "    worksheet.set_column(\"E:H\", 8)  # Detection metrics\n",
    "    worksheet.set_column(\"I:L\", 8)  # Fuzzing metrics\n",
    "\n",
    "    # Write headers\n",
    "    # Row 1: Main Headers\n",
    "    worksheet.merge_range(\"A1:A2\", \"Layer\", header_format)\n",
    "    worksheet.merge_range(\"B1:B2\", \"Lang\", header_format)\n",
    "    worksheet.merge_range(\"C1:C2\", \"Feature ID\", header_format)\n",
    "    worksheet.merge_range(\"D1:D2\", \"Interpretation\", header_format)\n",
    "\n",
    "    # Merged cells for Detection and Fuzzing\n",
    "    worksheet.merge_range(\"E1:H1\", \"Detection\", header_format)\n",
    "    worksheet.merge_range(\"I1:L1\", \"Fuzzing\", header_format)\n",
    "\n",
    "    # Row 2: Sub-headers for metrics\n",
    "    metric_sub_headers = [\"Accuracy\", \"F1 score\", \"Precision\", \"Recall\"]\n",
    "    detection_start_col = 4  # Column E\n",
    "    fuzzing_start_col = 8  # Column I\n",
    "\n",
    "    for i, sub_header in enumerate(metric_sub_headers):\n",
    "        worksheet.write(1, detection_start_col + i, sub_header, header_format)\n",
    "        worksheet.write(1, fuzzing_start_col + i, sub_header, header_format)\n",
    "\n",
    "    # Start writing data from the third row (index 2)\n",
    "    current_row = 2\n",
    "    for layer_key, feature_id_dict in layers_data.items():\n",
    "        for fid_key, details in feature_id_dict.items():\n",
    "            # Extract basic info\n",
    "            layer_val = details.get(\"Layer\", \"\")\n",
    "            lang_val = details.get(\"Lang\", \"\")\n",
    "            feature_id_val = details.get(\"Feature ID\", \"\")\n",
    "            interpretation_val = details.get(\"Interpretation\", \"\")\n",
    "            # Remove surrounding quotes from interpretation if they exist due to json dump\n",
    "            if interpretation_val.startswith('\"') and interpretation_val.endswith('\"'):\n",
    "                interpretation_val = interpretation_val[1:-1]\n",
    "\n",
    "            # Extract metrics\n",
    "            detection_metrics = {}\n",
    "            fuzz_metrics = {}\n",
    "            for metric_set in details.get(\"Metrics\", []):\n",
    "                if metric_set.get(\"score_type\") == \"detection\":\n",
    "                    detection_metrics = {\n",
    "                        \"accuracy\": metric_set.get(\"accuracy\"),\n",
    "                        \"f1_score\": metric_set.get(\"f1_score\"),\n",
    "                        \"precision\": metric_set.get(\"precision\"),\n",
    "                        \"recall\": metric_set.get(\"recall\"),\n",
    "                    }\n",
    "                elif metric_set.get(\"score_type\") == \"fuzz\":\n",
    "                    fuzz_metrics = {\n",
    "                        \"accuracy\": metric_set.get(\"accuracy\"),\n",
    "                        \"f1_score\": metric_set.get(\"f1_score\"),\n",
    "                        \"precision\": metric_set.get(\"precision\"),\n",
    "                        \"recall\": metric_set.get(\"recall\"),\n",
    "                    }\n",
    "\n",
    "            # Write data to cells with specified formats\n",
    "            worksheet.write(current_row, 0, layer_val, center_aligned_format)\n",
    "            worksheet.write(current_row, 1, lang_val, center_aligned_format)\n",
    "            worksheet.write(current_row, 2, feature_id_val, center_aligned_format)\n",
    "            worksheet.write(current_row, 3, interpretation_val, left_wrap_format)\n",
    "\n",
    "            # Write Detection metrics\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                detection_start_col + 0,\n",
    "                detection_metrics.get(\"accuracy\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                detection_start_col + 1,\n",
    "                detection_metrics.get(\"f1_score\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                detection_start_col + 2,\n",
    "                detection_metrics.get(\"precision\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                detection_start_col + 3,\n",
    "                detection_metrics.get(\"recall\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "\n",
    "            # Write Fuzzing metrics\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                fuzzing_start_col + 0,\n",
    "                fuzz_metrics.get(\"accuracy\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                fuzzing_start_col + 1,\n",
    "                fuzz_metrics.get(\"f1_score\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                fuzzing_start_col + 2,\n",
    "                fuzz_metrics.get(\"precision\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                fuzzing_start_col + 3,\n",
    "                fuzz_metrics.get(\"recall\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "\n",
    "            current_row += 1\n",
    "\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

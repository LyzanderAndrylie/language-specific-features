{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Features Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Collect Internal Activations](./images/decoder_only_model_internal_activations.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sae Features Activations](./images/internal_activations_to_sae.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_dir = Path().resolve().parent\n",
    "statistic_dir = project_dir / \"statistics\"\n",
    "script_dir = project_dir / \"scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(script_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton not installed, using eager implementation of sparse decoder.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from visualization import (\n",
    "    plot_all_layers,\n",
    "    plot_all_lang_feature_overlap,\n",
    "    plot_lang_feature_overlap_trend,\n",
    "    plot_all_co_occurrence,\n",
    "    plot_all_cross_co_occurrence,\n",
    "    plot_all_count_box_plots,\n",
    "    plot_lape_result,\n",
    "    plot_umap,\n",
    "    plot_ppl_change_matrix,\n",
    "    generate_ppl_change_matrix,\n",
    "    plot_metrics,\n",
    ")\n",
    "\n",
    "from feature_visualizer import (\n",
    "    generate_feature_activations_visualization,\n",
    ")\n",
    "\n",
    "from loader import (\n",
    "    load_layer_to_summary,\n",
    "    load_lang_to_dataset_token_activations,\n",
    "    load_lang_to_dataset_token_activations_aggregate,\n",
    "    load_all_interpretations,\n",
    ")\n",
    "\n",
    "from const import lang_choices_to_qualified_name, layer_to_index\n",
    "\n",
    "from delphi.log.result_analysis import get_metrics_per_latent, load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_xnli = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"facebook/xnli\",\n",
    "    \"split\": \"train\",\n",
    "    \"languages\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"hi\",\n",
    "        \"es\",\n",
    "        \"th\",\n",
    "        \"bg\",\n",
    "        \"ru\",\n",
    "        \"tr\",\n",
    "        \"vi\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_pawsx = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"google-research-datasets/paws-x\",\n",
    "    \"split\": \"train\",\n",
    "    \"languages\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"es\",\n",
    "        \"ja\",\n",
    "        \"ko\",\n",
    "        \"zh\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_flores = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"openlanguagedata/flores_plus\",\n",
    "    \"split\": \"dev\",\n",
    "    \"languages\": [\n",
    "        \"eng_Latn\",\n",
    "        \"deu_Latn\",\n",
    "        \"fra_Latn\",\n",
    "        \"ita_Latn\",\n",
    "        \"por_Latn\",\n",
    "        \"hin_Deva\",\n",
    "        \"spa_Latn\",\n",
    "        \"tha_Thai\",\n",
    "        \"bul_Cyrl\",\n",
    "        \"rus_Cyrl\",\n",
    "        \"tur_Latn\",\n",
    "        \"vie_Latn\",\n",
    "        \"jpn_Jpan\",\n",
    "        \"kor_Hang\",\n",
    "        \"cmn_Hans\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_summary_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")\n",
    "\n",
    "df_layers_llama_xnli = load_layer_to_summary(\n",
    "    data_path_summary_xnli, config_xnli[\"layers\"], config_xnli[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(df_layers_llama_xnli, config_xnli, range_y=[0, 40_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_xnli = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    config_xnli[\"layers\"],\n",
    "    config_xnli[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_xnli.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_facebook_xnli.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layers_llama_pawsx = load_layer_to_summary(\n",
    "    data_path_pawsx, config_pawsx[\"layers\"], config_pawsx[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(df_layers_llama_pawsx, config_pawsx, range_y=[0, 40_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_pawsx = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_pawsx,\n",
    "    config_pawsx[\"layers\"],\n",
    "    config_pawsx[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_pawsx.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_google-research-datasets_paws-x.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XNLI and PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_xnli, config_xnli, df_layers_llama_pawsx, config_pawsx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_xnli,\n",
    "    config_xnli,\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLORES+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layers_llama_flores = load_layer_to_summary(\n",
    "    data_path_flores, config_flores[\"layers\"], config_flores[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(\n",
    "    df_layers_llama_flores, config_flores, range_y=[0, 40_000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_flores = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_flores,\n",
    "    config_flores[\"layers\"],\n",
    "    config_flores[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_flores.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_gsarti_flores_101.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flores-101 with XNLI and PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores, config_flores, df_layers_llama_xnli, config_xnli\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    "    df_layers_llama_xnli,\n",
    "    config_xnli,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores, config_flores, df_layers_llama_pawsx, config_pawsx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Index Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_xnli[\"model\"].split(\"/\")[-1]\n",
    "sae_model_name = config_xnli[\"sae\"][\"model\"].split(\"/\")[-1]\n",
    "\n",
    "out_path = (\n",
    "    project_dir / \"visualization\" / \"feature_index\" / model / sae_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 25\n",
    "layer = \"model.layers.0.mlp\"\n",
    "\n",
    "model = config_flores[\"model\"]\n",
    "sae_model = config_flores[\"sae\"][\"model\"]\n",
    "layers = config_flores[\"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    layer,\n",
    "    config_xnli[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "lang_to_dataset_token_activations_pawsx = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_pawsx,\n",
    "    layer,\n",
    "    config_pawsx[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "lang_to_dataset_token_activations_flores = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_flores,\n",
    "    layer,\n",
    "    config_flores[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "dataset_lang_to_dataset_token_activations = {\n",
    "    \"xnli\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_xnli,\n",
    "        \"config\": {**config_xnli},\n",
    "    },\n",
    "    \"paws-x\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_pawsx,\n",
    "        \"config\": {**config_pawsx},\n",
    "    },\n",
    "    \"flores\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_flores,\n",
    "        \"config\": {**config_flores},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_info = {\n",
    "    \"feature_index\": feature_index,\n",
    "    \"layer\": layer,\n",
    "    \"lang\": \"None\",\n",
    "    \"selected_prob\": \"-\",\n",
    "    \"entropy\": \"-\",\n",
    "    \"interpretation\": \"-\",\n",
    "    \"metrics\": [\n",
    "        {\n",
    "            \"score_type\": \"-\",\n",
    "            \"true_positives\": \"-\",\n",
    "            \"true_negatives\": \"-\",\n",
    "            \"false_positives\": \"-\",\n",
    "            \"false_negatives\": \"-\",\n",
    "            \"total_examples\": \"-\",\n",
    "            \"total_positives\": \"-\",\n",
    "            \"total_negatives\": \"-\",\n",
    "            \"failed_count\": \"-\",\n",
    "            \"precision\": \"-\",\n",
    "            \"recall\": \"-\",\n",
    "            \"f1_score\": \"-\",\n",
    "            \"accuracy\": \"-\",\n",
    "            \"true_positive_rate\": \"-\",\n",
    "            \"true_negative_rate\": \"-\",\n",
    "            \"false_positive_rate\": \"-\",\n",
    "            \"false_negative_rate\": \"-\",\n",
    "            \"positive_class_ratio\": \"-\",\n",
    "            \"negative_class_ratio\": \"-\",\n",
    "            \"auc\": None,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "generate_feature_activations_visualization(\n",
    "    dataset_lang_to_dataset_token_activations,\n",
    "    feature_index,\n",
    "    feature_info,\n",
    "    model,\n",
    "    layer,\n",
    "    sae_model,\n",
    "    out_path,\n",
    "    lang_choices_to_qualified_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_10_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_10_by_entropy.pt\"\n",
    ")\n",
    "\n",
    "lape_top_10_result = torch.load(lape_top_10_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_top_10_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_10_by_entropy\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-10 Language-Specific Features by Entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_10_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_10_by_freq.pt\"\n",
    ")\n",
    "\n",
    "lape_top_10_result = torch.load(lape_top_10_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_top_10_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_10_by_freq\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-10 Language-Specific Features by Frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_neuron_result_path = (\n",
    "    project_dir\n",
    "    / \"mlp_acts_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / \"lape_neuron.pt\"\n",
    ")\n",
    "\n",
    "lape_neuron_result = torch.load(lape_neuron_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_neuron_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/lape_neuron\"\n",
    "    ),\n",
    "    title=\"Distribution of Language-specific Neurons\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_1_per_layer_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_1_per_layer_by_entropy.pt\"\n",
    ")\n",
    "\n",
    "lape_result_top_1_per_layer = torch.load(lape_top_1_per_layer_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_result_top_1_per_layer,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_1_per_layer_by_entropy\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-1 per Layer Language-Specific Features by Entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_1_per_layer_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_1_per_layer_by_freq.pt\"\n",
    ")\n",
    "\n",
    "lape_result_top_1_per_layer = torch.load(lape_top_1_per_layer_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_result_top_1_per_layer,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_1_per_layer_by_freq\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-1 per Layer Language-Specific Features by Frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_all_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_all\"\n",
    "    ),\n",
    "    title=\"Distribution of LAPE for all Language-Specific Features\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language-Specific Features Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_metrics_to_nested_dict(df):\n",
    "    result = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        layer = row['layer']\n",
    "        latent_idx = row['latent_idx']\n",
    "        values = row.drop(['layer', 'latent_idx'])\n",
    "        values = values.apply(lambda x: round(x, 3) if isinstance(x, float) else x)\n",
    "\n",
    "        layer_key = f\"model.{layer}\"\n",
    "\n",
    "        if layer_key not in result:\n",
    "            result[layer_key] = {}\n",
    "        if latent_idx not in result[layer_key]:\n",
    "            result[layer_key][latent_idx] = []\n",
    "\n",
    "        result[layer_key][latent_idx].append(values.to_dict())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_folder = project_dir / \"interpret_sae_features\" / \"explanations\"\n",
    "\n",
    "scores_path = (\n",
    "    project_dir\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"scores\"\n",
    ")\n",
    "\n",
    "visualize_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"scores\"\n",
    ")\n",
    "\n",
    "hookpoints = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretations = load_all_interpretations(interpretation_folder)\n",
    "latent_df, counts = load_data(scores_path, hookpoints)\n",
    "df_metrics = get_metrics_per_latent(latent_df)\n",
    "metrics = convert_df_metrics_to_nested_dict(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_flores[\"model\"]\n",
    "sae_model = config_flores[\"sae\"][\"model\"]\n",
    "model_name = config_flores[\"model\"].split(\"/\")[-1]\n",
    "sae_model_name = config_flores[\"sae\"][\"model\"].split(\"/\")[-1]\n",
    "layers = config_flores[\"layers\"]\n",
    "\n",
    "sorted_lang = lape_all_result[\"sorted_lang\"]\n",
    "\n",
    "for lang in tqdm(sorted_lang, desc=\"Processing languages\"):\n",
    "    lang_index = sorted_lang.index(lang)\n",
    "\n",
    "    for layer in tqdm(layers, desc=\"Processing layers\", leave=False):\n",
    "        layer_index = layer_to_index[layer]\n",
    "        lang_final_indices = lape_all_result[\"final_indice\"][lang_index][\n",
    "            layer_index\n",
    "        ].tolist()\n",
    "\n",
    "        if len(lang_final_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        layer = layers[layer_index]\n",
    "\n",
    "        lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "            data_path_dataset_token_activations_xnli,\n",
    "            layer,\n",
    "            config_xnli[\"languages\"],\n",
    "            lang_final_indices,\n",
    "        )\n",
    "\n",
    "        lang_to_dataset_token_activations_pawsx = (\n",
    "            load_lang_to_dataset_token_activations(\n",
    "                data_path_dataset_token_activations_pawsx,\n",
    "                layer,\n",
    "                config_pawsx[\"languages\"],\n",
    "                lang_final_indices,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        lang_to_dataset_token_activations_flores = (\n",
    "            load_lang_to_dataset_token_activations(\n",
    "                data_path_dataset_token_activations_flores,\n",
    "                layer,\n",
    "                config_flores[\"languages\"],\n",
    "                lang_final_indices,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset_lang_to_dataset_token_activations = {\n",
    "            \"xnli\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_xnli,\n",
    "                \"config\": {**config_xnli},\n",
    "            },\n",
    "            \"paws-x\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_pawsx,\n",
    "                \"config\": {**config_pawsx},\n",
    "            },\n",
    "            \"flores\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_flores,\n",
    "                \"config\": {**config_flores},\n",
    "            },\n",
    "        }\n",
    "\n",
    "        out_path = (\n",
    "            project_dir\n",
    "            / \"visualization\"\n",
    "            / \"feature_index\"\n",
    "            / model_name\n",
    "            / sae_model_name\n",
    "            / layer\n",
    "            / lang\n",
    "        )\n",
    "\n",
    "        selected_probs = lape_all_result['features_info'][lang][\"selected_probs\"]\n",
    "        entropies = lape_all_result['features_info'][lang][\"entropies\"]\n",
    "        \n",
    "        for feature_index in tqdm(lang_final_indices, desc=\"Processing indices\", leave=False):\n",
    "            try:\n",
    "                file_path = out_path / f\"feature_{feature_index}.html\"\n",
    "\n",
    "                if file_path.exists():\n",
    "                    continue\n",
    "                    \n",
    "                arg_index = lape_all_result['features_info'][lang][\"indicies\"].index((layer_index, feature_index))\n",
    "\n",
    "                feature_info = {\n",
    "                    \"feature_index\": feature_index,\n",
    "                    \"layer\": layer,\n",
    "                    \"lang\": lang,\n",
    "                    \"selected_prob\": round(selected_probs[arg_index].item(), ndigits=3),\n",
    "                    \"entropy\": round(entropies[arg_index].item(), ndigits=3),\n",
    "                    \"interpretation\": interpretations[layer][feature_index],\n",
    "                    \"metrics\": metrics[layer][feature_index],\n",
    "                }\n",
    "\n",
    "                generate_feature_activations_visualization(\n",
    "                    dataset_lang_to_dataset_token_activations,\n",
    "                    feature_index,\n",
    "                    feature_info,\n",
    "                    model,\n",
    "                    layer,\n",
    "                    sae_model,\n",
    "                    out_path,\n",
    "                    lang_choices_to_qualified_name,\n",
    "                    examples_per_section=40,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {lang} - {layer} - {feature_index}\")\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_umap.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"umap\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_xnli[\"model\"]\n",
    "sae_model = config_xnli[\"sae\"][\"model\"]\n",
    "layers = config_xnli[\"layers\"]\n",
    "\n",
    "plot_umap(lape_all_result, layers, model, sae_model, umap_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ppl_output_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"normal\"\n",
    "    / \"ppl.pt\"\n",
    ")\n",
    "\n",
    "normal_ppl_result = torch.load(normal_ppl_output_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuron Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    ")\n",
    "\n",
    "intervened_neuron_ppl_results = {\n",
    "    lang_choices_to_qualified_name[intervened_lang]: torch.load(\n",
    "        out_path / f\"ppl_{intervened_lang}.pt\", weights_only=False\n",
    "    )\n",
    "    for intervened_lang in config_flores[\"languages\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    "    / \"ppl_change_matrix.html\"\n",
    ")\n",
    "\n",
    "plot_ppl_change_matrix(\n",
    "    config_flores[\"languages\"],\n",
    "    normal_ppl_result,\n",
    "    intervened_neuron_ppl_results,\n",
    "    out_path,\n",
    "    title=\"PPL Change Matrix for Neuron Interventions\",\n",
    "    num_examples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAE Feature Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"sae_intervention\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    \"top_10/entropy/max/mult_0.2\",\n",
    "    \"top_10/entropy/max/mult_-0.2\",\n",
    "    \"top_1_per_layer/entropy/avg/mult_1\",\n",
    "    \"top_1_per_layer/entropy/avg/mult_-1\",\n",
    "    \"top_1_per_layer/entropy/max/mult_0.2\",\n",
    "    \"top_1_per_layer/entropy/max/mult_-0.2\",\n",
    "    \"top_1_per_layer/freq/avg/mult_-1\",\n",
    "    \"all/entropy/max/mult_0.2\",\n",
    "    \"all/entropy/max/mult_-0.2\",\n",
    "    \"all/entropy/max/mult_-0.3\",\n",
    "    \"all/entropy/max/mult_-0.4\",\n",
    "]\n",
    "\n",
    "generate_ppl_change_matrix(\n",
    "    configs,\n",
    "    config_flores[\"model\"],\n",
    "    config_flores[\"dataset\"],\n",
    "    config_flores[\"languages\"],\n",
    "    in_path,\n",
    "    normal_ppl_result,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_path = (\n",
    "    project_dir\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"min-max\"\n",
    "    / \"metrics.json\"\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"min-max\"\n",
    ")\n",
    "\n",
    "metric = json.load(open(metric_path, \"r\"))\n",
    "\n",
    "plot_metrics(metric, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_path = (\n",
    "    project_dir\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"count\"\n",
    "    / \"metrics.json\"\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"count\"\n",
    ")\n",
    "\n",
    "metric = json.load(open(metric_path, \"r\"))\n",
    "\n",
    "plot_metrics(metric, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Combine data from both tables\n",
    "data_lower = {\n",
    "    'Language': ['de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'bg', 'ru', 'tr', 'vi', 'ja', 'ko', 'zh'],\n",
    "    'Alpha': [0.4, 0.3, 0.4, 0.2, 0.175, 0.5, 0.375, 0.4, 0.5, 0.25, 0.3, 0.3, 0.4, 0.3],\n",
    "    'Change_Count': [17, 29, 10, 17, 29, 42, 18, 8, 27, 16, 11, 9, 16, 28],\n",
    "    'Change_Incoherent': [0, 0, 3, 0, 19, 0, 6, 0, 2, 1, 0, 4, 4, 1],\n",
    "    'Change_Partially_Coherent': [3, 15, 4, 7, 7, 10, 12, 5, 15, 13, 7, 3, 11, 12],\n",
    "    'Change_Coherent': [14, 14, 3, 10, 3, 32, 0, 3, 10, 2, 4, 2, 1, 15],\n",
    "    'Unchange_Count': [83, 71, 90, 83, 71, 58, 82, 92, 73, 84, 89, 91, 84, 72],\n",
    "    'Unchange_Incoherent': [2, 0, 0, 5, 2, 0, 0, 1, 2, 0, 2, 6, 3, 1],\n",
    "    'Unchange_Partially_Coherent': [7, 0, 8, 16, 3, 3, 11, 30, 4, 17, 7, 10, 18, 3],\n",
    "    'Unchange_Coherent': [74, 71, 82, 62, 64, 55, 71, 61, 67, 67, 80, 75, 63, 68]\n",
    "}\n",
    "\n",
    "data_higher = {\n",
    "    'Language': ['en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th', 'bg', 'ru', 'tr', 'vi', 'ja', 'ko', 'zh'],\n",
    "    'Alpha': [-1.2, 0.5, 0.4, 0.5, 0.25, 0.2, 0.8, 0.4, 0.5, 0.6, 0.3, 0.4, 0.4, 0.5, 0.4],\n",
    "    'Change_Count': [5, 27, 38, 23, 12, 30, 45, 45, 22, 34, 27, 18, 19, 43, 66],\n",
    "    'Change_Incoherent': [1, 2, 14, 20, 3, 23, 1, 37, 12, 9, 11, 4, 8, 24, 7],\n",
    "    'Change_Partially_Coherent': [3, 13, 14, 3, 7, 5, 26, 8, 10, 12, 11, 9, 10, 18, 32],\n",
    "    'Change_Coherent': [1, 12, 10, 0, 2, 2, 18, 0, 0, 13, 5, 5, 1, 1, 27],\n",
    "    'Unchange_Count': [95, 73, 62, 77, 88, 70, 55, 55, 78, 66, 73, 82, 81, 57, 34],\n",
    "    'Unchange_Incoherent': [8, 3, 1, 2, 28, 9, 0, 2, 3, 15, 6, 11, 9, 6, 1],\n",
    "    'Unchange_Partially_Coherent': [10, 15, 0, 4, 17, 3, 1, 11, 32, 5, 8, 12, 10, 8, 2],\n",
    "    'Unchange_Coherent': [77, 55, 61, 71, 43, 58, 54, 41, 43, 46, 59, 59, 62, 43, 31]\n",
    "}\n",
    "\n",
    "# Combine both datasets\n",
    "df_lower = pd.DataFrame(data_lower)\n",
    "df_lower['Table'] = 'Lower α'\n",
    "\n",
    "df_higher = pd.DataFrame(data_higher)\n",
    "df_higher['Table'] = 'Higher α'\n",
    "\n",
    "# Remove English from higher as it's a special case with negative alpha\n",
    "df_higher_no_en = df_higher[df_higher['Language'] != 'en'].copy()\n",
    "\n",
    "# Combine dataframes\n",
    "df_combined = pd.concat([df_lower, df_higher_no_en])\n",
    "\n",
    "# Find languages that appear in both tables\n",
    "common_languages = set(df_lower['Language']).intersection(set(df_higher_no_en['Language']))\n",
    "\n",
    "# Create a dataframe with paired data for languages that appear in both tables\n",
    "paired_data = []\n",
    "for lang in common_languages:\n",
    "    lower_row = df_lower[df_lower['Language'] == lang].iloc[0]\n",
    "    higher_row = df_higher_no_en[df_higher_no_en['Language'] == lang].iloc[0]\n",
    "    \n",
    "    paired_data.append({\n",
    "        'Language': lang,\n",
    "        'Alpha_Lower': lower_row['Alpha'],\n",
    "        'Alpha_Higher': higher_row['Alpha'],\n",
    "        'Change_Count_Lower': lower_row['Change_Count'],\n",
    "        'Change_Count_Higher': higher_row['Change_Count'],\n",
    "        'Change_Incoherent_Lower': lower_row['Change_Incoherent'],\n",
    "        'Change_Incoherent_Higher': higher_row['Change_Incoherent'],\n",
    "        'Change_Partially_Coherent_Lower': lower_row['Change_Partially_Coherent'],\n",
    "        'Change_Partially_Coherent_Higher': higher_row['Change_Partially_Coherent'],\n",
    "        'Change_Coherent_Lower': lower_row['Change_Coherent'],\n",
    "        'Change_Coherent_Higher': higher_row['Change_Coherent']\n",
    "    })\n",
    "\n",
    "df_paired = pd.DataFrame(paired_data)\n",
    "\n",
    "# Calculate percentages of coherence categories within the Changed texts\n",
    "df_paired['Change_Incoherent_Pct_Lower'] = df_paired['Change_Incoherent_Lower'] / df_paired['Change_Count_Lower'] * 100\n",
    "df_paired['Change_Partially_Coherent_Pct_Lower'] = df_paired['Change_Partially_Coherent_Lower'] / df_paired['Change_Count_Lower'] * 100\n",
    "df_paired['Change_Coherent_Pct_Lower'] = df_paired['Change_Coherent_Lower'] / df_paired['Change_Count_Lower'] * 100\n",
    "\n",
    "df_paired['Change_Incoherent_Pct_Higher'] = df_paired['Change_Incoherent_Higher'] / df_paired['Change_Count_Higher'] * 100\n",
    "df_paired['Change_Partially_Coherent_Pct_Higher'] = df_paired['Change_Partially_Coherent_Higher'] / df_paired['Change_Count_Higher'] * 100\n",
    "df_paired['Change_Coherent_Pct_Higher'] = df_paired['Change_Coherent_Higher'] / df_paired['Change_Count_Higher'] * 100\n",
    "\n",
    "# Sort by alpha difference to see the effect of increasing alpha\n",
    "df_paired['Alpha_Diff'] = df_paired['Alpha_Higher'] - df_paired['Alpha_Lower']\n",
    "df_paired = df_paired.sort_values(by='Alpha_Diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ordered language list\n",
    "ordered_languages = [\n",
    "    \"de\",\n",
    "    \"fr\",\n",
    "    \"it\",\n",
    "    \"pt\",\n",
    "    \"hi\",\n",
    "    \"es\",\n",
    "    \"th\",\n",
    "    \"bg\",\n",
    "    \"ru\",\n",
    "    \"tr\",\n",
    "    \"vi\",\n",
    "    \"ja\",\n",
    "    \"ko\",\n",
    "    \"zh\",\n",
    "]\n",
    "\n",
    "# Sort the paired dataframe according to the ordered language list\n",
    "df_paired[\"Language_Order\"] = df_paired[\"Language\"].apply(\n",
    "    lambda x: (\n",
    "        ordered_languages.index(x) if x in ordered_languages else len(ordered_languages)\n",
    "    )\n",
    ")\n",
    "df_paired = df_paired.sort_values(\"Language_Order\").reset_index(drop=True)\n",
    "\n",
    "# Figure 1: Comparing change in language generation at different alpha values\n",
    "fig1 = go.Figure()\n",
    "\n",
    "# Add lines for each coherence category\n",
    "fig1.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_paired[\"Language\"],\n",
    "        y=df_paired[\"Change_Count_Lower\"],\n",
    "        mode=\"markers+lines\",\n",
    "        name=\"Changed Text Count (Lower α)\",\n",
    "        marker=dict(size=10, color=\"blue\"),\n",
    "        line=dict(width=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig1.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_paired[\"Language\"],\n",
    "        y=df_paired[\"Change_Count_Higher\"],\n",
    "        mode=\"markers+lines\",\n",
    "        name=\"Changed Text Count (Higher α)\",\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        line=dict(width=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add alpha values as annotations\n",
    "for i, row in df_paired.iterrows():\n",
    "    fig1.add_annotation(\n",
    "        x=row[\"Language\"],\n",
    "        y=row[\"Change_Count_Lower\"],\n",
    "        text=f\"α={row['Alpha_Lower']}\",\n",
    "        showarrow=False,\n",
    "        yshift=-20,\n",
    "        font=dict(size=10, color=\"blue\"),\n",
    "    )\n",
    "    fig1.add_annotation(\n",
    "        x=row[\"Language\"],\n",
    "        y=row[\"Change_Count_Higher\"],\n",
    "        text=f\"α={row['Alpha_Higher']}\",\n",
    "        showarrow=False,\n",
    "        yshift=10,\n",
    "        font=dict(size=10, color=\"red\"),\n",
    "    )\n",
    "\n",
    "fig1.update_layout(\n",
    "    title=\"Impact of Increasing Scaling Factor (α) on Language Generation\",\n",
    "    xaxis_title=\"Target Language\",\n",
    "    yaxis_title=\"Count of Texts Changed to Target Language\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    hovermode=\"x unified\",\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "fig1.update_xaxes(\n",
    "    categoryorder=\"array\",\n",
    "    categoryarray=ordered_languages,\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig1.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig1.write_image(\n",
    "    output_path / \"impact_of_increasing_scaling_factor_on_language_generation.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Coherence breakdown as stacked bars\n",
    "fig2 = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Lower α Values', 'Higher α Values'),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Convert dataframe to long format for easier plotting\n",
    "coherence_data = []\n",
    "for i, row in df_paired.iterrows():\n",
    "    # Lower alpha values\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Lower',\n",
    "        'Alpha': row['Alpha_Lower'],\n",
    "        'Category': 'Coherent', \n",
    "        'Percentage': row['Change_Coherent_Pct_Lower']\n",
    "    })\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Lower',\n",
    "        'Alpha': row['Alpha_Lower'],\n",
    "        'Category': 'Partially Coherent', \n",
    "        'Percentage': row['Change_Partially_Coherent_Pct_Lower']\n",
    "    })\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Lower',\n",
    "        'Alpha': row['Alpha_Lower'],\n",
    "        'Category': 'Incoherent', \n",
    "        'Percentage': row['Change_Incoherent_Pct_Lower']\n",
    "    })\n",
    "    \n",
    "    # Higher alpha values\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Higher',\n",
    "        'Alpha': row['Alpha_Higher'],\n",
    "        'Category': 'Coherent', \n",
    "        'Percentage': row['Change_Coherent_Pct_Higher']\n",
    "    })\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Higher',\n",
    "        'Alpha': row['Alpha_Higher'],\n",
    "        'Category': 'Partially Coherent', \n",
    "        'Percentage': row['Change_Partially_Coherent_Pct_Higher']\n",
    "    })\n",
    "    coherence_data.append({\n",
    "        'Language': row['Language'], \n",
    "        'Alpha Value': 'Higher',\n",
    "        'Alpha': row['Alpha_Higher'],\n",
    "        'Category': 'Incoherent', \n",
    "        'Percentage': row['Change_Incoherent_Pct_Higher']\n",
    "    })\n",
    "\n",
    "df_coherence = pd.DataFrame(coherence_data)\n",
    "\n",
    "\n",
    "# Create color map for coherence categories\n",
    "color_map = {\n",
    "    'Coherent': 'rgb(53, 167, 107)',\n",
    "    'Partially Coherent': 'rgb(253, 174, 97)',\n",
    "    'Incoherent': 'rgb(215, 48, 39)'\n",
    "}\n",
    "\n",
    "# Plot lower alpha coherence breakdown\n",
    "for category in ['Coherent', 'Partially Coherent', 'Incoherent']:\n",
    "    df_cat = df_coherence[(df_coherence['Alpha Value'] == 'Lower') & \n",
    "                          (df_coherence['Category'] == category)]\n",
    "    \n",
    "    # Reorder data according to language_order\n",
    "    df_cat = df_cat.set_index('Language').reindex(ordered_languages).reset_index()\n",
    "    \n",
    "    fig2.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_cat['Language'],\n",
    "            y=df_cat['Percentage'],\n",
    "            name=category,\n",
    "            marker_color=color_map[category],\n",
    "            legendgroup=category,\n",
    "            showlegend=True,\n",
    "            text=[f\"{val:.1f}%\" for val in df_cat['Percentage']],\n",
    "            textposition='inside',\n",
    "            textfont=dict(color='white', size=10),\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Plot higher alpha coherence breakdown\n",
    "for category in ['Coherent', 'Partially Coherent', 'Incoherent']:\n",
    "    df_cat = df_coherence[(df_coherence['Alpha Value'] == 'Higher') & \n",
    "                          (df_coherence['Category'] == category)]\n",
    "    \n",
    "    # Reorder data according to language_order\n",
    "    df_cat = df_cat.set_index('Language').reindex(ordered_languages).reset_index()\n",
    "    \n",
    "    fig2.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_cat['Language'],\n",
    "            y=df_cat['Percentage'],\n",
    "            name=category,\n",
    "            marker_color=color_map[category],\n",
    "            legendgroup=category,\n",
    "            showlegend=False,\n",
    "            text=[f\"{val:.1f}%\" for val in df_cat['Percentage']],\n",
    "            textposition='inside',\n",
    "            textfont=dict(color='white', size=10),\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Add alpha values as annotations on x-axis\n",
    "for col, alpha_val in enumerate(['Lower', 'Higher'], 1):\n",
    "    for i, lang in enumerate(ordered_languages):\n",
    "        alpha = df_paired[df_paired['Language'] == lang][f'Alpha_{alpha_val}'].values[0]\n",
    "        fig2.add_annotation(\n",
    "            x=lang,\n",
    "            y=-10,\n",
    "            text=f\"α={alpha}\",\n",
    "            showarrow=False,\n",
    "            xref=f'x{col}',\n",
    "            yref=f'y{col}',\n",
    "            font=dict(size=10)\n",
    "        )\n",
    "\n",
    "fig2.update_layout(\n",
    "    title='Impact of Scaling Factor (α) on Text Coherence in Changed Languages',\n",
    "    barmode='stack',\n",
    "    legend=dict(orientation=\"h\", yanchor=\"top\", y=1.115, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    yaxis=dict(title='Percentage (%)', range=[0, 100]),\n",
    "    yaxis2=dict(title='Percentage (%)', range=[0, 100]),\n",
    "    xaxis=dict(title='Target Language'),\n",
    "    xaxis2=dict(title='Target Language')\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig2.write_image(\n",
    "    output_path / \"impact_of_scaling_factor_on_text_coherence_changed.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# (Assumes df_lower, df_higher_no_en and df_paired already exist as in your setup)\n",
    "\n",
    "# 1) Build Figure 2b\n",
    "fig2b = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Lower α Values\", \"Higher α Values\"),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n",
    ")\n",
    "\n",
    "# 2) Collect “unchanged” coherence data, but normalize over the sum of the three categories\n",
    "unchanged_coherence_data = []\n",
    "for _, row in df_paired.iterrows():\n",
    "    lang = row[\"Language\"]\n",
    "    lower = df_lower.loc[df_lower[\"Language\"] == lang].iloc[0]\n",
    "    higher = df_higher_no_en.loc[df_higher_no_en[\"Language\"] == lang].iloc[0]\n",
    "\n",
    "    # Lower α\n",
    "    total_lower = (\n",
    "        lower[\"Unchange_Coherent\"]\n",
    "        + lower[\"Unchange_Partially_Coherent\"]\n",
    "        + lower[\"Unchange_Incoherent\"]\n",
    "    )\n",
    "    if total_lower > 0:\n",
    "        unchanged_coherence_data += [\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Coherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Coherent\"] / total_lower * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Partially Coherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Partially_Coherent\"] / total_lower * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Incoherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Incoherent\"] / total_lower * 100,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "    # Higher α\n",
    "    total_higher = (\n",
    "        higher[\"Unchange_Coherent\"]\n",
    "        + higher[\"Unchange_Partially_Coherent\"]\n",
    "        + higher[\"Unchange_Incoherent\"]\n",
    "    )\n",
    "    if total_higher > 0:\n",
    "        unchanged_coherence_data += [\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Coherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Coherent\"] / total_higher * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Partially Coherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Partially_Coherent\"]\n",
    "                / total_higher\n",
    "                * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Incoherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Incoherent\"] / total_higher * 100,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "df_unchanged_coherence = pd.DataFrame(unchanged_coherence_data)\n",
    "\n",
    "# 3) Plot it\n",
    "color_map = {\n",
    "    \"Coherent\": \"rgb(53, 167, 107)\",\n",
    "    \"Partially Coherent\": \"rgb(253, 174, 97)\",\n",
    "    \"Incoherent\": \"rgb(215, 48, 39)\",\n",
    "}\n",
    "language_order = df_paired[\"Language\"].tolist()\n",
    "\n",
    "for col, alpha_val in enumerate([\"Lower\", \"Higher\"], start=1):\n",
    "    for category in [\"Coherent\", \"Partially Coherent\", \"Incoherent\"]:\n",
    "        df_cat = (\n",
    "            df_unchanged_coherence.query(\n",
    "                \"`Alpha Value` == @alpha_val and Category == @category\"\n",
    "            )\n",
    "            .set_index(\"Language\")\n",
    "            .reindex(language_order)\n",
    "            .reset_index()\n",
    "        )\n",
    "        fig2b.add_trace(\n",
    "            go.Bar(\n",
    "                x=df_cat[\"Language\"],\n",
    "                y=df_cat[\"Percentage\"],\n",
    "                name=category,\n",
    "                marker_color=color_map[category],\n",
    "                legendgroup=category,\n",
    "                showlegend=(col == 1),  # only show legend in first subplot\n",
    "                text=[f\"{v:.1f}%\" for v in df_cat[\"Percentage\"]],\n",
    "                textposition=\"inside\",\n",
    "                textfont=dict(color=\"white\", size=10),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "    # add α annotation under each language tick\n",
    "    for lang in language_order:\n",
    "        α = (\n",
    "            row[f\"Alpha_{alpha_val}\"]\n",
    "            if False\n",
    "            else df_paired.loc[\n",
    "                df_paired[\"Language\"] == lang, f\"Alpha_{alpha_val}\"\n",
    "            ].iloc[0]\n",
    "        )\n",
    "        fig2b.add_annotation(\n",
    "            x=lang,\n",
    "            y=-5,\n",
    "            text=f\"α={α}\",\n",
    "            showarrow=False,\n",
    "            xref=f\"x{col}\",\n",
    "            yref=f\"y{col}\",\n",
    "            font=dict(size=10),\n",
    "        )\n",
    "\n",
    "fig2b.update_layout(\n",
    "    title=\"Impact of Scaling Factor (α) on Text Coherence in Unchanged Languages\",\n",
    "    barmode=\"stack\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"top\", y=1.115, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    yaxis=dict(title=\"Percentage (%)\", range=[0, 100]),\n",
    "    yaxis2=dict(title=\"Percentage (%)\", range=[0, 100]),\n",
    "    xaxis=dict(title=\"Target Language\"),\n",
    "    xaxis2=dict(title=\"Target Language\"),\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig2b.write_image(\n",
    "    output_path / \"impact_of_scaling_factor_on_text_coherence_unchanged.pdf\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

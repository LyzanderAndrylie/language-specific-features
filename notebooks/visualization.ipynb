{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Features Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Collect Internal Activations](./images/decoder_only_model_internal_activations.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sae Features Activations](./images/internal_activations_to_sae.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_dir = Path().resolve().parent\n",
    "statistic_dir = project_dir / \"statistics\"\n",
    "script_dir = project_dir / \"scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(script_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from visualization import (\n",
    "    plot_all_layers,\n",
    "    plot_all_lang_feature_overlap,\n",
    "    plot_lang_feature_overlap_trend,\n",
    "    plot_all_co_occurrence,\n",
    "    plot_all_cross_co_occurrence,\n",
    "    plot_all_count_box_plots,\n",
    "    plot_lape_result,\n",
    "    plot_umap,\n",
    "    plot_ppl_change_matrix,\n",
    "    generate_ppl_change_matrix,\n",
    ")\n",
    "\n",
    "from feature_visualizer import (\n",
    "    generate_feature_activations_visualization,\n",
    ")\n",
    "\n",
    "from loader import (\n",
    "    load_layer_to_summary,\n",
    "    load_lang_to_dataset_token_activations,\n",
    "    load_lang_to_dataset_token_activations_aggregate,\n",
    "    load_all_interpretations,\n",
    ")\n",
    "\n",
    "from const import lang_choices_to_qualified_name, layer_to_index\n",
    "\n",
    "from delphi.log.result_analysis import get_metrics_per_latent, load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_xnli = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"facebook/xnli\",\n",
    "    \"split\": \"train\",\n",
    "    \"languages\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"hi\",\n",
    "        \"es\",\n",
    "        \"th\",\n",
    "        \"bg\",\n",
    "        \"ru\",\n",
    "        \"tr\",\n",
    "        \"vi\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_pawsx = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"google-research-datasets/paws-x\",\n",
    "    \"split\": \"train\",\n",
    "    \"languages\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"es\",\n",
    "        \"ja\",\n",
    "        \"ko\",\n",
    "        \"zh\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_flores = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"openlanguagedata/flores_plus\",\n",
    "    \"split\": \"dev\",\n",
    "    \"languages\": [\n",
    "        \"eng_Latn\",\n",
    "        \"deu_Latn\",\n",
    "        \"fra_Latn\",\n",
    "        \"ita_Latn\",\n",
    "        \"por_Latn\",\n",
    "        \"hin_Deva\",\n",
    "        \"spa_Latn\",\n",
    "        \"tha_Thai\",\n",
    "        \"bul_Cyrl\",\n",
    "        \"rus_Cyrl\",\n",
    "        \"tur_Latn\",\n",
    "        \"vie_Latn\",\n",
    "        \"jpn_Jpan\",\n",
    "        \"kor_Hang\",\n",
    "        \"cmn_Hans\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_summary_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")\n",
    "\n",
    "df_layers_llama_xnli = load_layer_to_summary(\n",
    "    data_path_summary_xnli, config_xnli[\"layers\"], config_xnli[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(df_layers_llama_xnli, config_xnli, range_y=[0, 40_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_xnli = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    config_xnli[\"layers\"],\n",
    "    config_xnli[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_xnli.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_facebook_xnli.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layers_llama_pawsx = load_layer_to_summary(\n",
    "    data_path_pawsx, config_pawsx[\"layers\"], config_pawsx[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(df_layers_llama_pawsx, config_pawsx, range_y=[0, 40_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_pawsx = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_pawsx,\n",
    "    config_pawsx[\"layers\"],\n",
    "    config_pawsx[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_pawsx.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_google-research-datasets_paws-x.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XNLI and PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_xnli, config_xnli, df_layers_llama_pawsx, config_pawsx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_xnli,\n",
    "    config_xnli,\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLORES+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layers_llama_flores = load_layer_to_summary(\n",
    "    data_path_flores, config_flores[\"layers\"], config_flores[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(\n",
    "    df_layers_llama_flores, config_flores, range_y=[0, 40_000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_flores = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_flores,\n",
    "    config_flores[\"layers\"],\n",
    "    config_flores[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_flores.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_gsarti_flores_101.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flores-101 with XNLI and PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores, config_flores, df_layers_llama_xnli, config_xnli\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    "    df_layers_llama_xnli,\n",
    "    config_xnli,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores, config_flores, df_layers_llama_pawsx, config_pawsx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Index Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_xnli[\"model\"].split(\"/\")[-1]\n",
    "sae_model_name = config_xnli[\"sae\"][\"model\"].split(\"/\")[-1]\n",
    "\n",
    "out_path = (\n",
    "    project_dir / \"visualization\" / \"feature_index\" / model / sae_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 25\n",
    "layer = \"model.layers.0.mlp\"\n",
    "\n",
    "model = config_flores[\"model\"]\n",
    "sae_model = config_flores[\"sae\"][\"model\"]\n",
    "layers = config_flores[\"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    layer,\n",
    "    config_xnli[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "lang_to_dataset_token_activations_pawsx = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_pawsx,\n",
    "    layer,\n",
    "    config_pawsx[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "lang_to_dataset_token_activations_flores = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_flores,\n",
    "    layer,\n",
    "    config_flores[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "dataset_lang_to_dataset_token_activations = {\n",
    "    \"xnli\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_xnli,\n",
    "        \"config\": {**config_xnli},\n",
    "    },\n",
    "    \"paws-x\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_pawsx,\n",
    "        \"config\": {**config_pawsx},\n",
    "    },\n",
    "    \"flores\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_flores,\n",
    "        \"config\": {**config_flores},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_info = {\n",
    "    \"feature_index\": feature_index,\n",
    "    \"layer\": layer,\n",
    "    \"lang\": \"None\",\n",
    "    \"selected_prob\": \"-\",\n",
    "    \"entropy\": \"-\",\n",
    "    \"interpretation\": \"-\",\n",
    "    \"metrics\": [\n",
    "        {\n",
    "            \"score_type\": \"-\",\n",
    "            \"true_positives\": \"-\",\n",
    "            \"true_negatives\": \"-\",\n",
    "            \"false_positives\": \"-\",\n",
    "            \"false_negatives\": \"-\",\n",
    "            \"total_examples\": \"-\",\n",
    "            \"total_positives\": \"-\",\n",
    "            \"total_negatives\": \"-\",\n",
    "            \"failed_count\": \"-\",\n",
    "            \"precision\": \"-\",\n",
    "            \"recall\": \"-\",\n",
    "            \"f1_score\": \"-\",\n",
    "            \"accuracy\": \"-\",\n",
    "            \"true_positive_rate\": \"-\",\n",
    "            \"true_negative_rate\": \"-\",\n",
    "            \"false_positive_rate\": \"-\",\n",
    "            \"false_negative_rate\": \"-\",\n",
    "            \"positive_class_ratio\": \"-\",\n",
    "            \"negative_class_ratio\": \"-\",\n",
    "            \"auc\": None,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "generate_feature_activations_visualization(\n",
    "    dataset_lang_to_dataset_token_activations,\n",
    "    feature_index,\n",
    "    feature_info,\n",
    "    model,\n",
    "    layer,\n",
    "    sae_model,\n",
    "    out_path,\n",
    "    lang_choices_to_qualified_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_10_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_10_by_entropy.pt\"\n",
    ")\n",
    "\n",
    "lape_top_10_result = torch.load(lape_top_10_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_top_10_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_10_by_entropy\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-10 Language-Specific Features by Entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_10_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_10_by_freq.pt\"\n",
    ")\n",
    "\n",
    "lape_top_10_result = torch.load(lape_top_10_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_top_10_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_10_by_freq\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-10 Language-Specific Features by Frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_neuron_result_path = (\n",
    "    project_dir\n",
    "    / \"mlp_acts_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / \"lape_neuron.pt\"\n",
    ")\n",
    "\n",
    "lape_neuron_result = torch.load(lape_neuron_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_neuron_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/lape_neuron\"\n",
    "    ),\n",
    "    title=\"Distribution of Language-specific Neurons\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_1_per_layer_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_1_per_layer_by_entropy.pt\"\n",
    ")\n",
    "\n",
    "lape_result_top_1_per_layer = torch.load(lape_top_1_per_layer_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_result_top_1_per_layer,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_1_per_layer_by_entropy\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-1 per Layer Language-Specific Features by Entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_1_per_layer_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_1_per_layer_by_freq.pt\"\n",
    ")\n",
    "\n",
    "lape_result_top_1_per_layer = torch.load(lape_top_1_per_layer_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_result_top_1_per_layer,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_1_per_layer_by_freq\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-1 per Layer Language-Specific Features by Frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_all_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_all\"\n",
    "    ),\n",
    "    title=\"Distribution of LAPE for all Language-Specific Features\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language-Specific Features Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_metrics_to_nested_dict(df):\n",
    "    result = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        layer = row['layer']\n",
    "        latent_idx = row['latent_idx']\n",
    "        values = row.drop(['layer', 'latent_idx'])\n",
    "        values = values.apply(lambda x: round(x, 3) if isinstance(x, float) else x)\n",
    "\n",
    "        layer_key = f\"model.{layer}\"\n",
    "\n",
    "        if layer_key not in result:\n",
    "            result[layer_key] = {}\n",
    "        if latent_idx not in result[layer_key]:\n",
    "            result[layer_key][latent_idx] = []\n",
    "\n",
    "        result[layer_key][latent_idx].append(values.to_dict())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_folder = project_dir / \"interpret_sae_features\" / \"explanations\"\n",
    "\n",
    "scores_path = (\n",
    "    project_dir\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"scores\"\n",
    ")\n",
    "\n",
    "visualize_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"interpret_sae_features\"\n",
    "    / \"scores\"\n",
    ")\n",
    "\n",
    "hookpoints = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretations = load_all_interpretations(interpretation_folder)\n",
    "latent_df, counts = load_data(scores_path, hookpoints)\n",
    "df_metrics = get_metrics_per_latent(latent_df)\n",
    "metrics = convert_df_metrics_to_nested_dict(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_flores[\"model\"]\n",
    "sae_model = config_flores[\"sae\"][\"model\"]\n",
    "model_name = config_flores[\"model\"].split(\"/\")[-1]\n",
    "sae_model_name = config_flores[\"sae\"][\"model\"].split(\"/\")[-1]\n",
    "layers = config_flores[\"layers\"]\n",
    "\n",
    "sorted_lang = lape_all_result[\"sorted_lang\"]\n",
    "\n",
    "for lang in tqdm(sorted_lang, desc=\"Processing languages\"):\n",
    "    lang_index = sorted_lang.index(lang)\n",
    "\n",
    "    for layer in tqdm(layers, desc=\"Processing layers\", leave=False):\n",
    "        layer_index = layer_to_index[layer]\n",
    "        lang_final_indices = lape_all_result[\"final_indice\"][lang_index][\n",
    "            layer_index\n",
    "        ].tolist()\n",
    "\n",
    "        if len(lang_final_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        layer = layers[layer_index]\n",
    "\n",
    "        lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "            data_path_dataset_token_activations_xnli,\n",
    "            layer,\n",
    "            config_xnli[\"languages\"],\n",
    "            lang_final_indices,\n",
    "        )\n",
    "\n",
    "        lang_to_dataset_token_activations_pawsx = (\n",
    "            load_lang_to_dataset_token_activations(\n",
    "                data_path_dataset_token_activations_pawsx,\n",
    "                layer,\n",
    "                config_pawsx[\"languages\"],\n",
    "                lang_final_indices,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        lang_to_dataset_token_activations_flores = (\n",
    "            load_lang_to_dataset_token_activations(\n",
    "                data_path_dataset_token_activations_flores,\n",
    "                layer,\n",
    "                config_flores[\"languages\"],\n",
    "                lang_final_indices,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset_lang_to_dataset_token_activations = {\n",
    "            \"xnli\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_xnli,\n",
    "                \"config\": {**config_xnli},\n",
    "            },\n",
    "            \"paws-x\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_pawsx,\n",
    "                \"config\": {**config_pawsx},\n",
    "            },\n",
    "            \"flores\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_flores,\n",
    "                \"config\": {**config_flores},\n",
    "            },\n",
    "        }\n",
    "\n",
    "        out_path = (\n",
    "            project_dir\n",
    "            / \"visualization\"\n",
    "            / \"feature_index\"\n",
    "            / model_name\n",
    "            / sae_model_name\n",
    "            / layer\n",
    "            / lang\n",
    "        )\n",
    "\n",
    "        selected_probs = lape_all_result['features_info'][lang][\"selected_probs\"]\n",
    "        entropies = lape_all_result['features_info'][lang][\"entropies\"]\n",
    "        \n",
    "        for feature_index in tqdm(lang_final_indices, desc=\"Processing indices\", leave=False):\n",
    "            try:\n",
    "                file_path = out_path / f\"feature_{feature_index}.html\"\n",
    "\n",
    "                if file_path.exists():\n",
    "                    continue\n",
    "                    \n",
    "                arg_index = lape_all_result['features_info'][lang][\"indicies\"].index((layer_index, feature_index))\n",
    "\n",
    "                feature_info = {\n",
    "                    \"feature_index\": feature_index,\n",
    "                    \"layer\": layer,\n",
    "                    \"lang\": lang,\n",
    "                    \"selected_prob\": round(selected_probs[arg_index].item(), ndigits=3),\n",
    "                    \"entropy\": round(entropies[arg_index].item(), ndigits=3),\n",
    "                    \"interpretation\": interpretations[layer][feature_index],\n",
    "                    \"metrics\": metrics[layer][feature_index],\n",
    "                }\n",
    "\n",
    "                generate_feature_activations_visualization(\n",
    "                    dataset_lang_to_dataset_token_activations,\n",
    "                    feature_index,\n",
    "                    feature_info,\n",
    "                    model,\n",
    "                    layer,\n",
    "                    sae_model,\n",
    "                    out_path,\n",
    "                    lang_choices_to_qualified_name,\n",
    "                    examples_per_section=40,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {lang} - {layer} - {feature_index}\")\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_umap.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"umap\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_xnli[\"model\"]\n",
    "sae_model = config_xnli[\"sae\"][\"model\"]\n",
    "layers = config_xnli[\"layers\"]\n",
    "\n",
    "plot_umap(lape_all_result, layers, model, sae_model, umap_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ppl_output_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"normal\"\n",
    "    / \"ppl.pt\"\n",
    ")\n",
    "\n",
    "normal_ppl_result = torch.load(normal_ppl_output_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuron Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    ")\n",
    "\n",
    "intervened_neuron_ppl_results = {\n",
    "    lang_choices_to_qualified_name[intervened_lang]: torch.load(\n",
    "        out_path / f\"ppl_{intervened_lang}.pt\", weights_only=False\n",
    "    )\n",
    "    for intervened_lang in config_flores[\"languages\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    "    / \"ppl_change_matrix.html\"\n",
    ")\n",
    "\n",
    "plot_ppl_change_matrix(\n",
    "    config_flores[\"languages\"],\n",
    "    normal_ppl_result,\n",
    "    intervened_neuron_ppl_results,\n",
    "    out_path,\n",
    "    title=\"PPL Change Matrix for Neuron Interventions\",\n",
    "    num_examples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAE Feature Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"sae_intervention\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    \"top_10/entropy/max/mult_0.2\",\n",
    "    \"top_10/entropy/max/mult_-0.2\",\n",
    "    \"top_1_per_layer/entropy/avg/mult_1\",\n",
    "    \"top_1_per_layer/entropy/avg/mult_-1\",\n",
    "    \"top_1_per_layer/entropy/max/mult_0.2\",\n",
    "    \"top_1_per_layer/entropy/max/mult_-0.2\",\n",
    "    \"top_1_per_layer/freq/avg/mult_-1\",\n",
    "    \"all/entropy/max/mult_0.2\"\n",
    "]\n",
    "\n",
    "generate_ppl_change_matrix(\n",
    "    configs,\n",
    "    config_flores[\"model\"],\n",
    "    config_flores[\"dataset\"],\n",
    "    config_flores[\"languages\"],\n",
    "    in_path,\n",
    "    normal_ppl_result,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
